[
 {
  "topic": "Week 7 Lectures\n ",
  "content": "Signature-based Selection\n",
  "key_words": [
   "week",
   "7",
   "lecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Indexing with Signatures\n",
  "content": "Signature-based indexing:\n designed for pmr queries \u00a0 (conjunction of equalities)\n does not try to achieve better than O(n) performance\n attempts to provide an \"efficient\" linear scan\n Each tuple is associated with a signature\n a compact (lossy) descriptor for the tuple\n formed by combining information from multiple attributes\n stored in a signature file, parallel to data file\n Instead of scanning/testing tuples, do pre-filtering via signatures.\n",
  "key_words": [
   "indexing",
   "with",
   "signature"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Indexing with Signatures\n",
  "content": "File organisation for signature indexing (two files)\n One signature slot per tuple slot; unused signature slots are zeroed.\n Record placement is independent of signatures \u21d2 can use with other indexing.\n",
  "key_words": [
   "indexing",
   "with",
   "signature"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Signatures\n",
  "content": "A signature \"summarises\" the data in one tuple\n A tuple consists of N attribute values A1 .. An\n A codeword cw(Ai) is\n a bit-string, m bits long, where k bits are set to 1 \u00a0(k \u226a m)\n derived from the value of a single attribute Ai\n A tuple descriptor (signature) is built by combining cw(Ai), i=1..n\n could combine by overlaying or concatenating codewords\n aim to have roughly half of the bits set to 1\n",
  "key_words": [
   "signature"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Generating Codewords\n",
  "content": "Generating a k-in-m codeword for attribute Ai\n bits codeword(char *attr_value, int m, int k) {    int  nbits = 0;   // count of set bits    bits cword = 0;   // assuming m <= 32 bits    srandom(hash(attr_value));    while (nbits < k) {       int i = random() % m;       if (((1 << i) & cword) == 0) {          cword |= (1 << i);          nbits++;       }    }    return cword;  // m-bits with k 1-bits and m-k 0-bits }",
  "key_words": [
   "generating",
   "codewords"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Superimposed Codewords (SIMC)\n",
  "content": "In a superimposed codewords (simc) indexing scheme\n a tuple descriptor is formed by overlaying attribute codewords\n A tuple descriptor desc(r) is\n a bit-string, m bits long, where j \u2264 nk bits are set to 1\n desc(r)\u00a0=\u00a0cw(A1) OR cw(A2) OR ... OR cw(An)\n Method (assuming all n attributes are used in descriptor):\n bits desc = 0  for (i = 1; i <= n; i++) {    bits cw = codeword(A[i])    desc = desc | cw }",
  "key_words": [
   "superimposed",
   "codewords",
   "(simc)"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "SIMC Example\n",
  "content": "Consider the following tuple (from bank deposit database)\n Branch AcctNo Name Amount\n Perryridge 102 Hayes 400\n It has the following codewords/descriptor (for m = 12, \u00a0 k = 2 )\n Ai cw(Ai)\n Perryridge 010000000001\n 102 000000000011\n Hayes 000001000100\n 400 000010000100\n desc(r) 010011000111\n",
  "key_words": [
   "simc",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "SIMC Queries\n",
  "content": "To answer query q in SIMC\n first generate a query descriptor desc(q)\n then use the query descriptor to search the signature file\n desc(q) is formed by OR of codewords for known attributes.\n E.g. consider the query (Perryridge, ?, ?, ?).\n Ai cw(Ai)\n Perryridge 010000000001\n ? 000000000000\n ? 000000000000\n ? 000000000000\n desc(q) 010000000001\n",
  "key_words": [
   "simc",
   "query"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "SIMC Queries\n",
  "content": "Once we have a query descriptor, we search the signature file:\n pagesToCheck = {} for each descriptor D[i] in signature file {     if (matches(D[i],desc(q))) {         pid = pageOf(tupleID(i))         pagesToCheck = pagesToCheck \u222a pid     } } for each P in pagesToCheck {     Buf = getPage(f,P)     check tuples in Buf for answers } // where ... #define matches(rdesc,qdesc)                ((rdesc & qdesc) == qdesc)",
  "key_words": [
   "simc",
   "query"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Example SIMC Query\n",
  "content": "Consider the query and the example database:\n Signature Deposit Record\n 010000000001 (Perryridge,?,?,?)\n 100101001001 (Brighton,217,Green,750)\n 010011000111 (Perryridge,102,Hayes,400)\n 101001001001 (Downtown,101,Johnshon,512)\n 101100000011 (Mianus,215,Smith,700)\n 010101010101 (Clearview,117,Throggs,295)\n 100101010011 (Redwood,222,Lindsay,695)\n Gives two matches: \u00a0one true match, \u00a0one false match.\n",
  "key_words": [
   "example",
   "simc",
   "query"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "SIMC Parameters\n",
  "content": "False match probablity pF \u00a0=\u00a0 likelihood of a false match\n How to reduce likelihood of false matches?\n use different hash function for each attribute \u00a0 (hi for Ai)\n increase descriptor size (m)\n choose k so that \u2245 half of bits are set\n  Larger m means reading more descriptor data.\n Having k too high \u00a0\u21d2\u00a0 increased overlapping. Having k too low \u00a0\u21d2\u00a0 increased hash collisions.\n",
  "key_words": [
   "simc",
   "parameter"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "SIMC Parameters\n",
  "content": " 1. start by choosing acceptable pF  \u00a0 (e.g. pF \u2264 10-5 i.e. one false match in 10,000)\n 2. then choose m and k to achieve no more than this pF.\n Formulae to derive m and k given pF and n:\n k \u00a0=\u00a0 1/loge2 . loge ( 1/pF )\n m \u00a0=\u00a0 ( 1/loge 2 )2 . n . loge ( 1/pF )\n",
  "key_words": [
   "simc",
   "parameter"
  ],
  "question": [
   "How to determine \"optimal\" m and k?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "Query Cost for SIMC\n",
  "content": "Cost to answer pmr query: Costpmr = bD + bq\n read r descriptors on bD descriptor pages\n then read bq data pages and check for matches\n bD = ceil( r/cD ) \u00a0and\u00a0 cD = floor(B/ceil(m/8))\n E.g. m=64, \u00a0 B=8192, \u00a0 r=104 \u00a0\u00a0\u00a0\u21d2\u00a0\u00a0\u00a0 cD = 1024, \u00a0 bD=10\n bq includes pages with rq matching tuples and rF false matches\n Expected false matches = rF \u00a0=\u00a0 (r - rq).pF \u00a0\u2245\u00a0 r.pF \u00a0 if rq \u226a r\n E.g. Worst bq = rq+rF, \u00a0 Best bq = 1, \u00a0 Avg bq = ceil(b(rq+rF)/r)\n",
  "key_words": [
   "query",
   "cost",
   "for",
   "simc"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 1: SIMC Query Cost\n",
  "content": "Consider a SIMC-indexed database with the following properties\n all pages are B = 8192 bytes\n tuple descriptors have m = 64 bits ( = 8 bytes)\n total records r = 102,400, \u00a0 records/page c = 100\n",
  "key_words": [
   "exercise",
   "1",
   "simc",
   "query",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "false match probability pF = 1/1000\n",
  "content": "answer set has 1000 tuples from 100 pages\n 90% of false matches occur on data pages with true match\n 10% of false matches are distributed 1 per page\n Calculate the total number of pages read in answering the query.\n",
  "key_words": [
   "false",
   "match",
   "probability",
   "pf",
   "="
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Page-level SIMC\n",
  "content": "SIMC has one descriptor per tuple ... potentially inefficient.\n Alternative approach: one descriptor for each data page.\n Every attribute of every tuple in page contributes to descriptor.\n Size of page descriptor (PD) (clearly larger than tuple descriptor):\n use above formulae but with c.n \"attributes\"\n E.g. n = 4, c = 128, pF = 10-3 \u00a0 \u21d2 \u00a0 m \u2245 7000bits \u2245 900bytes\n Typically, pages are 1..8KB \u00a0\u21d2\u00a0 8..64 PD/page (NPD).\n",
  "key_words": [
   "page-level",
   "simc"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Page-Level SIMC Files\n",
  "content": "File organisation for page-level superimposed codeword index\n",
  "key_words": [
   "page-level",
   "simc",
   "file"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 2: Page-level SIMC Query Cost\n",
  "content": "Consider a SIMC-indexed database with the following properties\n all pages are B = 8192 bytes\n page descriptors have m = 4096 bits ( = 512 bytes)\n total records r = 102,400, \u00a0 records/page c = 100\n",
  "key_words": [
   "exercise",
   "2",
   "page-level",
   "simc",
   "query",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "false match probability pF = 1/1000\n",
  "content": "answer set has 1000 tuples from 100 pages\n 90% of false matches occur on data pages with true match\n 10% of false matches are distributed 1 per page\n Calculate the total number of pages read in answering the query.\n",
  "key_words": [
   "false",
   "match",
   "probability",
   "pf",
   "="
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Page-Level SIMC Files\n",
  "content": "Improvement: store b m-bit page descriptors as m b-bit \"bit-slices\"\n ",
  "key_words": [
   "page-level",
   "simc",
   "file"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Page-Level SIMC Files\n",
  "content": "At query time\n matches = ~0  //all ones for each bit i set to 1 in desc(q) {    slice = fetch bit-slice i    matches = matches & slice } for each bit i set to 1 in matches {    fetch page i    scan page for matching records }  Effective because desc(q) typically has less than half bits set to 1\n",
  "key_words": [
   "page-level",
   "simc",
   "file"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 3: Bit-sliced SIMC Query Cost\n",
  "content": "Consider a SIMC-indexed database with the following properties\n all pages are B = 8192 bytes\n r = 102,400, \u00a0 c = 100, \u00a0 b = 1024\n page descriptors have m = 4096 bits ( = 512 bytes)\n bit-slices have b = 1024 bits ( = 128 bytes)\n",
  "key_words": [
   "exercise",
   "3",
   "bit-sliced",
   "simc",
   "query",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "false match probability pF = 1/1000\n",
  "content": "query descriptor has k = 10 bits set to 1\n answer set has 1000 tuples from 100 pages\n 90% of false matches occur on data pages with true match\n 10% of false matches are distributed 1 per page\n Calculate the total number of pages read in answering the query.\n Similarity Retrieval\n",
  "key_words": [
   "false",
   "match",
   "probability",
   "pf",
   "="
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Similarity Selection\n",
  "content": "Relational selection is based on a boolean condition C\n evaluate C for each tuple t\n if C(t) is true, add t to result set\n if C(t) is false, t is not part of solution\n result is a set of tuples { t1, t2, ..., tn } all of which satisfy C\n Uses for relational selection:\n precise matching on structured data\n using individual attributes with known, exact values\n",
  "key_words": [
   "similarity",
   "selection"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity Selection\n",
  "content": "Similarity selection is used in contexts where\n cannot define a precise matching condition\n can define a measure d of \"distance\" between tuples\n d=0 is an exact match, d>0 is less accurate match\n result is a list of pairs [ (t1,d1), (t2,d2), ..., (tn,dn) ] \u00a0 (ordered by di)\n Uses for similarity matching:\n text or multimedia (image/music) retrieval\n ranked queries in conventional databases\n",
  "key_words": [
   "similarity",
   "selection"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Similarity-based Retrieval\n",
  "content": "Similarity-based retrieval typically works as follows:\n query is given as a query object q \u00a0 (e.g. sample image)\n system finds objects that are like q \u00a0 (i.e. small distance)\n The system can measure distance between any object and q ...\n How to restrict solution set to only the \"most similar\" objects:\n threshold dmax \u00a0 (only objects t such that dist(t,q) \u2264 dmax)\n count k \u00a0 (k closest objects (k nearest neighbours))\n",
  "key_words": [
   "similarity-based",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity-based Retrieval\n",
  "content": "Tuple structure for storing such data typically contains\n id to uniquely identify object \u00a0 (e.g. PostgreSQL oid)\n metadata \u00a0 (e.g. artist, title, genre, date taken, ...)\n value of object itself \u00a0 (e.g. PostgreSQL BLOB or bytea)\n Properties of typical distance functions \u00a0 (on objects x,y,z)\n dist(x,y) \u2265 0, \u00a0\u00a0\u00a0 dist(x,x) = 0, \u00a0\u00a0\u00a0 dist(x,y) = dist(y,x)\n dist(x,z) < dist(x,y) + dist(y,z) \u00a0 (triangle inequality)\n Distance calculation often requires substantial computational effort\n",
  "key_words": [
   "similarity-based",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity-based Retrieval\n",
  "content": "Naive approach to similarity-based retrieval\n q = ...    // query object dmax = ... // dmax > 0  =>  using threshold knn = ...  // knn > 0   =>  using nearest-neighbours Dists = [] // empty list foreach tuple t in R {     d = dist(t.val, q)     insert (t.oid,d) into Dists  // sorted on d } n = 0;  Results = [] foreach (i,d) in Dists {     if (dmax > 0 && d > dmax) break;     if (knn > 0 && ++n > knn) break;     insert (i,d) into Results  // sorted on d } return Results; Cost \u00a0=\u00a0 read all r feature vectors \u00a0+\u00a0 compute distance() for each\n",
  "key_words": [
   "similarity-based",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity-based Retrieval\n",
  "content": "For some applications, Cost(dist(x,y)) is comparable to Tr\n \u21d2 \u00a0 computing dist(t.val,q) for every tuple t is infeasible.\n To improve this aspect:\n compute feature vector which captures \"critical\" object properties\n store feature vectors \"in parallel\" with objects \u00a0 (cf. signatures)\n compute distance using feature vectors \u00a0 (not objects)\n i.e. replace dist(t,tq) by dist'(vec(t),vec(tq)) in previous algorithm.\n Further optimisation: dimension-reduction to make vectors smaller\n",
  "key_words": [
   "similarity-based",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity-based Retrieval\n",
  "content": "Content of feature vectors depends on application ...\n image ... colour histogram (e.g. 100's of values/dimensions)\n music ... loudness/pitch/tone (e.g. 100's of values/dimensions)\n text ... term frequencies (e.g. 1000's of values/dimensions)\n Typically use multiple features, concatenated into single vector.\n Feature vectors represent points in a very high-dimensional space.\n Query: feature vector representing one point in vh-dim space.\n Answer: list of objects \"near to\" query object in this space.\n",
  "key_words": [
   "similarity-based",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Example: Content-based Image Retrieval\n",
  "content": "User supplies a description or sample of desired image (features).\n System returns a ranked list of \"matching\" images from database.\n",
  "key_words": [
   "example",
   "content-based",
   "image",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Example: Content-based Image Retrieval\n",
  "content": "At the SQL level, this might appear as ...\n // relational matching create view Sunset as select image from MyPhotos where  title = 'Pittwater Sunset'        and taken = '2012-01-01'; // similarity matching with threshold create view SimilarSunsets as select title, image from   MyPhotos where  (image ~~ (select * from Sunset)) < 0.05 order  by (image ~~ (select * from Sunset)); where the (imaginary) ~~ operator measures distance between images.\n",
  "key_words": [
   "example",
   "content-based",
   "image",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Example: Content-based Image Retrieval\n",
  "content": "Implementing content-based retrieval requires ...\n a collection of \"pertinent\" image features\n e.g. colour, texture, shape, keywords, ...\n some way of describing/representing image features\n typically via a vector of numeric values\n a distance/similarity measure based on features\n e.g. Euclidean distance between two vectors\n \u00a0 dist(x,y) = \u221a( (x1-y1)2 + (x2-y2)2 + ... (xn-yn)2 )\n",
  "key_words": [
   "example",
   "content-based",
   "image",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Example: Content-based Image Retrieval\n",
  "content": "Inputs to content-based similarity-retrieval:\n a database of r objects \u00a0 (obj1,\u00a0obj2,\u00a0...,\u00a0objr) \u00a0 plus associated ...\n r \u00d7 n-dimensional feature vectors \u00a0 (vobj1,\u00a0vobj2,\u00a0...,\u00a0vobjr)\n a query image q with associated n-dimensional vector (vq)\n a distance measure \u00a0 D(vi,vj) : [0..1) \u00a0\u00a0 (D=0 \u2192 vi=vj)\n Outputs from content-based similarity-retrieval:\n a list of the k nearest objects in the database \u00a0 [a1, \u00a0 a2, \u00a0 ... \u00a0 ak]\n ordered by distance \u00a0 D(va1,vq) \u00a0\u2264\u00a0 D(va2,vq) \u00a0\u2264\u00a0 ... \u00a0\u2264\u00a0 D(vak,vq)\n",
  "key_words": [
   "example",
   "content-based",
   "image",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "Approaches to kNN Retrieval\n",
  "content": "Partition-based\n use auxiliary data structure to identify candidates\n space/data-partitioning methods: e.g. k-d-B-tree, R-tree, ...\n unfortunately, such methods \"fail\" when #dims > 10..20\n absolute upper bound on d before linear scan is best d = 610\n Approximation-based\n use approximating data structure to identify candidates\n signatures: VA-files\n projections: iDistance, LSH, MedRank, CurveIX, Pyramid\n",
  "key_words": [
   "approach",
   "to",
   "knn",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Approaches to kNN Retrieval\n",
  "content": "Above approaches mostly try to reduce number of objects considered.\n Other optimisations to make kNN retrieval faster\n reduce I/O by reducing size of vectors \u00a0 (compression, d-reduction)\n reduce I/O by placing \"similar\" records together \u00a0 (clustering)\n reduce I/O by remembering previous pages \u00a0 (caching)\n reduce cpu by making distance computation faster\n",
  "key_words": [
   "approach",
   "to",
   "knn",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Similarity Retrieval in PostgreSQL\n",
  "content": "PostgreSQL has always supported simple \"similarity\" on strings\n select * from Students where name like '%oo%'; select * from Students where name ~ '[Ss]mit'; Also provides support for ranked similarity on text values\n using tsvector data type \u00a0(stemmed, stopped feature vector for text)\n using tsquery data type \u00a0(stemmed, stopped feature vector for strings)\n using @@ similarity operator\n",
  "key_words": [
   "similarity",
   "retrieval",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Similarity Retrieval in PostgreSQL\n",
  "content": "Example of PostgreSQL text retrieval:\n create table Docs    ( id integer, title text, body text ); // add column to hold document feature vectors alter table Docs add column features tsvector; update Docs set features =    to_tsvector('english', title||' '||body); // ask query and get results in ranked order select title, ts_rank(d.features, query) as rank from   Docs d,        to_tsquery('potter|(roger&rabbit)') as query where  query @@ d.features order  by rank desc limit 10; For more details, see PostgreSQL documentation, Chapter 12.\n Implementing Join\n",
  "key_words": [
   "similarity",
   "retrieval",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Join\n",
  "content": "DBMSs are engines to store, combine and filter information.\n Join (\u22c8) is the primary means of combining information.\n Join is important and potentially expensive  Most common join condition: equijoin, e.g. (R.pk = S.fk)\n Join varieties (natural, inner, outer, semi, anti) all behave similarly.\n We consider three strategies for implementing join\n nested loop ... simple, widely applicable, inefficient without buffering\n sort-merge ... works best if tables are soted on join attributes\n hash-based ... requires good hash function and sufficient buffering\n",
  "key_words": [
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Join Example\n",
  "content": "Consider a university database with the schema:\n create table Student(    id     integer primary key,    name   text,  ... ); create table Enrolled(    stude  integer references Student(id),    subj   text references Subject(code),  ... ); create table Subject(    code   text primary key,    title  text,  ... );",
  "key_words": [
   "join",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Join Example\n",
  "content": "List names of students in all subjects, arranged by subject.\n SQL query to provide this information:\n select E.subj, S.name from   Student S, Enrolled E where  S.id = E.stude order  by E.subj, S.name; And its relational algebra equivalent:\n Sort[subj] ( Project[subj,name] ( Join[id=stude](Student,Enrolled) ) )\n   To simplify formulae, we denote Student by S and Enrolled by E\n",
  "key_words": [
   "join",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Join Example\n",
  "content": "Some database statistics:\n Sym Meaning Value\n rS # student records 20,000\n rE # enrollment records 80,000\n cS Student records/page 20\n cE Enrolled records/page 40\n bS # data pages in Student 1,000\n bE # data pages in Enrolled 2,000\n Also, in cost analyses below, N = number of memory buffers.\n",
  "key_words": [
   "join",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Join Example\n",
  "content": "Out = Student \u22c8 Enrolled relation statistics:\n Sym Meaning Value\n rOut # tuples in result 80,000\n COut result records/page 80\n bOut # data pages in result 1,000\n Notes:\n rOut ... one result tuple for each Enrolled tuple\n COut ... result tuples have only subj and name\n in analyses, ignore cost of writing result ... same in all methods\n Nested Loop Join\n",
  "key_words": [
   "join",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "Nested Loop Join\n",
  "content": "Basic strategy (R.a \u22c8 S.b):\n Result = {} for each page i in R {    pageR = getPage(R,i)    for each page j in S {       pageS = getPage(S,j)       for each pair of tuples tR,tS                        from pageR,pageS {          if (tR.a == tS.b)             Result = Result \u222a (tR:tS) }  }  } Needs input buffers for R and S, output buffer for \"joined\" tuples\n Terminology: R is outer relation, S is inner relation\n Cost = bR . bS \u00a0 ... \u00a0 ouch!\n",
  "key_words": [
   "nested",
   "loop",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Block Nested Loop Join\n",
  "content": "Method (for N memory buffers):\n read N-2-page chunk of R into memory buffers\n for each S page  \u00a0\u00a0\u00a0 check join condition on all (tR,tS) pairs in buffers\n repeat for all N-2-page chunks of R\n",
  "key_words": [
   "block",
   "nested",
   "loop",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Block Nested Loop Join\n",
  "content": "Best-case scenario: bR \u2264 N-2\n read bR pages of relation R into buffers\n while R is buffered, read bS pages of S\n Cost \u00a0 = \u00a0 bR + bS\n Typical-case scenario: bR > N-2\n read ceil(bR/N-2) chunks of pages from R\n for each chunk, read bS pages of S\n Cost \u00a0 = \u00a0 bR + bS . ceil(bR/N-2)\n Note: always requires rR.rS checks of the join condition\n",
  "key_words": [
   "block",
   "nested",
   "loop",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 4: Nested Loop Join Cost\n",
  "content": "Compute the cost (# pages fetched) of (S \u22c8 E)\n Sym Meaning Value\n rS # student records 20,000\n rE # enrollment records 80,000\n cS Student records/page 20\n cE Enrolled records/page 40\n bS # data pages in Student 1,000\n bE # data pages in Enrolled 2,000\n for N = 22, 202, 2002 and different inner/outer combinations\n",
  "key_words": [
   "exercise",
   "4",
   "nested",
   "loop",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Exercise 5: Nested Loop Join Cost (cont)\n",
  "content": "If the query in the above example was:\n select j.code, j.title, s.name from   Student s        join Enrolled e on (s.id=e.student)        join Subject j on (e.subj=j.code) how would this change the previous analysis?\n What join combinations are there?\n Assume 2000 subjects, with cJ = 10\n How large would the intermediate tuples be? What assumptions?\n Compute the cost (# pages fetched, # pages written) for N = 22\n",
  "key_words": [
   "exercise",
   "5",
   "nested",
   "loop",
   "join",
   "cost",
   "(cont)"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "... Block Nested Loop Join\n",
  "content": " Many queries have the form\n select * from R,S where r.i=s.j and r.x=k This would typically be evaluated as\n Join [i=j] ((Sel[r.x=k](R)), S)\n If |Sel[r.x=k](R)| is small \u21d2 may fit in memory (in small #buffers)\n",
  "key_words": [
   "block",
   "nested",
   "loop",
   "join"
  ],
  "question": [
   "Why block nested loop join is actually useful in practice ?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "Index Nested Loop Join\n",
  "content": "A problem with nested-loop join:\n needs repeated scans of entire inner relation S\n If there is an index on S, we can avoid such repeated scanning.\n Consider Join[R.i=S.j](R,S):\n for each tuple r in relation R {     use index to select tuples         from S where s.j = r.i     for each selected tuple s from S {         add (r,s) to result }   }",
  "key_words": [
   "index",
   "nested",
   "loop",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Index Nested Loop Join\n",
  "content": "This method requires:\n one scan of R relation (bR)\n only one buffer needed, since we use R tuple-at-a-time\n for each tuple in R (rR), one index lookup on S\n cost depends on type of index and number of results\n best case is when each R.i matches few S tuples\n Cost \u00a0 = \u00a0 bR + rR.SelS \u00a0\u00a0 (SelS is the cost of performing a select on S).\n Typical SelS \u00a0=\u00a0 1-2 (hashing) .. bq (unclustered index)\n Trade-off: \u00a0 rR.SelS \u00a0vs\u00a0 bR.bS, \u00a0 where \u00a0 bR \u226a rR and SelS \u226a bS\n",
  "key_words": [
   "index",
   "nested",
   "loop",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 6: Index Nested Loop Join Cost\n",
  "content": "Consider executing Join[i=j](S,T) with the following parameters:\n rS = 1000,\u00a0 bS = 50,\u00a0 rT = 3000,\u00a0 bT = 600\n S.i is primary key, and T has index on T.j\n T is sorted on T.j, each S tuple joins with 2 T tuples\n DBMS has N = 12 buffers available for the join\n Calculate the costs for evaluating the above join\n using block nested loop join\n using index nested loop join\n Costr = # pages read \u00a0 and \u00a0 Costj = # join-condition checks\n Sort-Merge Join\n",
  "key_words": [
   "exercise",
   "6",
   "index",
   "nested",
   "loop",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Sort-Merge Join\n",
  "content": "Basic approach:\n sort both relations on join attribute \u00a0 (reminder: Join[R.i=S.j](R,S))\n scan together using merge to form result (r,s) tuples\n Advantages:\n no need to deal with \"entire\" S relation for each r tuple\n deal with runs of matching R and S tuples\n Disadvantages:\n cost of sorting both relations \u00a0 (already sorted on join key?)\n some rescanning required when long runs of S tuples\n",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Sort-Merge Join\n",
  "content": "Method requires several cursors to scan sorted relations:\n r = current record in R relation\n s = start of current run in S relation\n ss = current record in current run in S relation\n",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Sort-Merge Join\n",
  "content": "Algorithm using query iterators/scanners:\n Query ri, si;  Tuple r,s;  ri = startScan(\"SortedR\"); si = startScan(\"SortedS\"); while ((r = nextTuple(ri)) != NULL        && (s = nextTuple(si)) != NULL) {     // align cursors to start of next common run     while (r != NULL && r.i < s.j)            r = nextTuple(ri);     if (r == NULL) break;     while (s != NULL && r.i > s.j)            s = nextTuple(si);     if (s == NULL) break;     // must have (r.i == s.j) here ...",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Sort-Merge Join\n",
  "content": "...     // remember start of current run in S     TupleID startRun = scanCurrent(si)     // scan common run, generating result tuples     while (r != NULL && r.i == s.j) {         while (s != NULL and s.j == r.i) {             addTuple(outbuf, combine(r,s));             if (isFull(outbuf)) {                 writePage(outf, outp++, outbuf);                 clearBuf(outbuf);             }             s = nextTuple(si);         }         r = nextTuple(ri);         setScan(si, startRun);     } }",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Sort-Merge Join\n",
  "content": "Buffer requirements:\n for sort phase:\n as many as possible (remembering that cost is O(logN) )\n if insufficient buffers, sorting cost can dominate\n for merge phase:\n one output buffer for result\n one input buffer for relation R\n (preferably) enough buffers for longest run in S\n",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Sort-Merge Join\n",
  "content": "Cost of sort-merge join.\n Step 1: sort each relation \u00a0 (if not already sorted):\n Cost = 2.bR (1 + logN-1(bR /N)) \u00a0+\u00a0 2.bS (1 + logN-1(bS /N))  \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0 (where N = number of memory buffers)\n Step 2: merge sorted relations:\n if every run of values in S fits completely in buffers,  merge requires single scan, \u00a0 Cost = bR + bS\n if some runs in of values in S are larger than buffers,  need to re-scan run for each corresponding value from R\n",
  "key_words": [
   "sort-merge",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Sort-Merge Join on Example\n",
  "content": "Case 1: \u00a0 Join[id=stude](Student,Enrolled)\n relations are not sorted on id#\n memory buffers N=32; all runs are of length < 30\n \u00a0\n  Cost = sort(S) + sort(E) + bS + bE\n = 2bS(1+log31(bS/32)) + 2bE(1+log31(bE/32)) + bS + bE\n = 2\u00d71000\u00d7(1+2) + 2\u00d72000\u00d7(1+2) + 1000 + 2000\n = 6000 + 12000 + 1000 + 2000\n = 21,000\n",
  "key_words": [
   "sort-merge",
   "join",
   "on",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... Sort-Merge Join on Example\n",
  "content": "Case 2: \u00a0 Join[id=stude](Student,Enrolled)\n Student and Enrolled already sorted on id#\n memory buffers N=4 (S input, 2 \u00d7 E input, output)\n 5% of the \"runs\" in E span two pages\n there are no \"runs\" in S, since id# is a primary key\n For the above, no re-scans of E runs are ever needed\n Cost \u00a0=\u00a0 2,000 + 1,000 \u00a0=\u00a0 3,000 \u00a0 (regardless of which relation is outer)\n",
  "key_words": [
   "sort-merge",
   "join",
   "on",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "Exercise 7: Sort-merge Join Cost\n",
  "content": "Consider executing Join[i=j](S,T) with the following parameters:\n rS = 1000,\u00a0 bS = 50,\u00a0 rT = 3000,\u00a0 bT = 150\n S.i is primary key, and T has index on T.j\n T is sorted on T.j, each S tuple joins with 2 T tuples\n DBMS has N = 42 buffers available for the join\n Calculate the cost for evaluating the above join\n using sort-merge join\n compute #pages read/written\n compute #join-condition checks performed\n Hash Join\n",
  "key_words": [
   "exercise",
   "7",
   "sort-merge",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Hash Join\n",
  "content": "Basic idea:\n use hashing as a technique to partition relations\n to avoid having to consider all pairs of tuples\n Requires sufficent memory buffers\n to hold substantial portions of partitions\n (preferably) to hold largest partition of outer relation\n Other issues:\n works only for equijoin \u00a0 R.i=S.j \u00a0 (but this is a common case)\n susceptible to data skew \u00a0 (or poor hash function)\n Variations: \u00a0 simple, \u00a0 grace, \u00a0 hybrid.\n",
  "key_words": [
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Simple Hash Join\n",
  "content": "Basic approach:\n hash part of outer relation R into memory buffers (build)\n scan inner relation S, using hash to search (probe)\n if R.i=S.j, then h(R.i)=h(S.j) \u00a0 (hash to same buffer)\n only need to check one memory buffer for each S tuple\n repeat until whole of R has been processed\n No overflows allowed in in-memory hash table\n works best with uniform hash function\n can be adversely affected by data/hash skew\n",
  "key_words": [
   "simple",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Simple Hash Join\n",
  "content": "Data flow:\n",
  "key_words": [
   "simple",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Simple Hash Join\n",
  "content": "Algorithm for simple hash join Join[R.i=S.j](R,S):\n for each tuple r in relation R {    if (buffer[h(R.i)] is full) {       for each tuple s in relation S {          for each tuple rr in buffer[h(S.j)] {             if ((rr,s) satisfies join condition) {                add (rr,s) to result       }  }  }       clear all hash table buffers    }    insert r into buffer[h(R.i)] } # join tests \u00a0\u2264\u00a0 rS.cR \u00a0\u00a0 (cf. nested-loop \u00a0rS.rR)\n # page reads depends on #buffers N and properties of data/hash.\n",
  "key_words": [
   "simple",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 8: Simple Hash Join Cost\n",
  "content": "Consider executing Join[i=j](R,S) with the following parameters:\n rR = 1000,\u00a0 bR = 50,\u00a0 rS = 3000,\u00a0 bS = 150, \u00a0cRes = 30\n R.i\u00a0 is primary key, each R tuple joins with 2 S tuples\n DBMS has N = 42 buffers available for the join\n data + hash have uniform distribution\n Calculate the cost for evaluating the above join\n using simple hash join\n compute #pages read/written\n compute #join-condition checks performed\n assume that hash table has L=0.75 for each partition\n",
  "key_words": [
   "exercise",
   "8",
   "simple",
   "hash",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Grace Hash Join\n",
  "content": "Basic approach (for R \u22c8 S ):\n partition both relations on join attribute using hashing (h1)\n load each partition of R into N-buffer hash table (h2)\n scan through corresponding partition of S to form results\n repeat until all partitions exhausted\n For best-case cost (O(bR + bS) ):\n need \u2265 \u221abR buffers to hold largest partition of outer relation\n If < \u221abR buffers or poor hash distribution\n need to scan some partitions of S multiple times\n",
  "key_words": [
   "grace",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Grace Hash Join\n",
  "content": "Partition phase (applied to both R and S):\n",
  "key_words": [
   "grace",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Grace Hash Join\n",
  "content": "Probe/join phase:\n The second hash function (h2) simply speeds up the matching process.  Without it, would need to scan entire R partition for each record in S partition.\n",
  "key_words": [
   "grace",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Grace Hash Join\n",
  "content": "Cost of grace hash join:\n #pages in all partition files of Rel \u2245 bRel \u00a0 (maybe slightly more)\n partition relation R ... \u00a0 Cost \u00a0=\u00a0 bR.Tr + bR.Tw \u00a0=\u00a0 2bR\n partition relation S ... \u00a0 Cost \u00a0=\u00a0 bS.Tr + bS.Tw \u00a0=\u00a0 2bS\n probe/join requires one scan of each (partitioned) relation  Cost \u00a0=\u00a0 bR + bS\n all hashing and comparison occurs in memory \u00a0 \u21d2 \u00a0 \u22450 cost\n Total Cost \u00a0 = \u00a0 2bR + 2bS + bR + bS \u00a0 = \u00a0 3 (bR + bS)\n",
  "key_words": [
   "grace",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 9: Grace Hash Join Cost\n",
  "content": "Consider executing Join[i=j](R,S) with the following parameters:\n rR = 1000,\u00a0 bR = 50,\u00a0 rS = 3000,\u00a0 bS = 150, \u00a0cRes = 30\n R.i\u00a0 is primary key, each R tuple joins with 2 S tuples\n DBMS has N = 43 buffers available for the join\n data + hash have reasonably uniform distribution\n Calculate the cost for evaluating the above join\n using Grace hash join\n compute #pages read/written\n compute #join-condition checks performed\n assume that no R partition is larger than 40 pages\n",
  "key_words": [
   "exercise",
   "9",
   "grace",
   "hash",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Exercise 10: Grace Hash Join Cost\n",
  "content": "Consider executing Join[i=j](R,S) with the following parameters:\n rR = 1000,\u00a0 bR = 50,\u00a0 rS = 3000,\u00a0 bS = 150, \u00a0cRes = 30\n R.i\u00a0 is primary key, each R tuple joins with 2 S tuples\n DBMS has N = 42 buffers available for the join\n data + hash have reasonably uniform distribution\n Calculate the cost for evaluating the above join\n using Grace hash join\n compute #pages read/written\n compute #join-condition checks performed\n assume that one R partition has 50 pages, others < 40 pages\n assume that the corresponding S partition has 30 pages\n",
  "key_words": [
   "exercise",
   "10",
   "grace",
   "hash",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Hybrid Hash Join\n",
  "content": "A variant of grace join if we have \u221abR < N < bR+2\n create k\u226aN partitions,\u00a0 m in memory,\u00a0 k-m on disk\n buffers: 1 input, k-m output, p = N-(k-m)-1 for in-memory partitions\n When we come to scan and partition S relation\n any tuple with hash in range 0..m-1 can be resolved\n other tuples are written to one of k partition files for S\n Final phase is same as grace join, but with only k partitions.\n Comparison:\n grace hash join creates N-1 partitions on disk\n hybrid hash join creates m (memory) + k (disk) partitions\n",
  "key_words": [
   "hybrid",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hybrid Hash Join\n",
  "content": "First phase of hybrid hash join with m=1 (partitioning R):\n",
  "key_words": [
   "hybrid",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hybrid Hash Join\n",
  "content": "Next phase of hybrid hash join with m=1 (partitioning S):\n",
  "key_words": [
   "hybrid",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hybrid Hash Join\n",
  "content": "Final phase of hybrid hash join with m=1 (finishing join):\n",
  "key_words": [
   "hybrid",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hybrid Hash Join\n",
  "content": "Some observations:\n with k partitions, each partition has expected size bR/k\n holding m partitions in memory needs \u2308mbR/k\u2309 buffers\n trade-off between in-memory partition space and #partitions\n Best-cost scenario:\n m = 1, \u00a0 k \u2245 \u2308bR/N\u2309 \u00a0\u00a0 (satisfying above constraint)\n Other notes:\n if N = bR+2, using block nested loop join is simpler\n cost depends on N (but less than grace hash join)\n",
  "key_words": [
   "hybrid",
   "hash",
   "join"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 11: Hybrid Hash Join Cost\n",
  "content": "Consider executing Join[i=j](R,S) with the following parameters:\n rR = 1000,\u00a0 bR = 50,\u00a0 rS = 3000,\u00a0 bS = 150, \u00a0cRes = 30\n R.i\u00a0 is primary key, each R tuple joins with 2 S tuples\n DBMS has N = 42 buffers available for the join\n data + hash have reasonably uniform distribution\n Calculate the cost for evaluating the above join\n using hybrid hash join with m=1, p=40\n compute #pages read/written\n compute #join-condition checks performed\n assume that no R partition is larger than 40 pages\n",
  "key_words": [
   "exercise",
   "11",
   "hybrid",
   "hash",
   "join",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Join Summary\n",
  "content": "No single join algorithm is superior in some overall sense.\n Which algorithm is best for a given query depends on:\n sizes of relations being joined, \u00a0 size of buffer pool\n any indexing on relations, \u00a0 whether relations are sorted\n which attributes and operations are used in the query\n number of tuples in S matching each tuple in R\n distribution of data values (uniform, skew, ...)\n Choosing the \"best\" join algorithm is critical because the cost difference between best and worst case can be very\n large.\n E.g. \u00a0 Join[id=stude](Student,Enrolled): \u00a0 3,000 ... 2,000,000\n",
  "key_words": [
   "join",
   "summary"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Join in PostgreSQL\n",
  "content": "Join implementations are under: src/backend/executor\n PostgreSQL suports three kinds of join:\n nested loop join (nodeNestloop.c)\n sort-merge join \u00a0 (nodeMergejoin.c)\n hash join \u00a0 (nodeHashjoin.c) \u00a0 (hybrid hash join)\n Query optimiser chooses appropriate join, by considering\n physical characteristics of tables being joined\n estimated selectivity (likely number of result tuples)\n",
  "key_words": [
   "join",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 12: Outer Join?\n",
  "content": "Above discussion was all in terms of theta inner-join.\n How would the algorithms above adapt to outer join?\n Consider the following ...\n select * from   R left outer join S on (R.i = S.j)  select * from   R right outer join S on (R.i = S.j)  select * from   R full outer join S on (R.i = S.j) Query Evaluation\n",
  "key_words": [
   "exercise",
   "12",
   "outer",
   "join?"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Query Evaluation\n",
  "content": "",
  "key_words": [
   "query",
   "evaluation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Evaluation\n",
  "content": "A query in SQL:\n states what kind of answers are required (declarative)\n does not say how they should be computed (procedural)\n A query evaluator/processor :\n takes declarative description of query \u00a0 (in SQL)\n parses query to internal representation \u00a0 (relational algebra)\n determines plan for answering query \u00a0 (expressed as DBMS ops)\n executes method via DBMS engine \u00a0 (to produce result tuples)\n  Some DBMSs can save query plans for later re-use.\n",
  "key_words": [
   "query",
   "evaluation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Evaluation\n",
  "content": "Internals of the query evaluation \"black-box\":\n",
  "key_words": [
   "query",
   "evaluation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Evaluation\n",
  "content": "DBMSs provide several \"flavours\" of each RA operation.\n For example:\n several \"versions\" of selection (\u03c3) are available\n each version is effective for a particular kind of selection, e.g\n select * from R where id = 100  -- hashing select * from S                 -- Btree index where age > 18 and age < 35 select * from T                 -- MALH file where a = 1 and b = 'a' and c = 1.4 Similarly, \u03c0 and \u22c8 have versions to match specific query types.\n",
  "key_words": [
   "query",
   "evaluation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Evaluation\n",
  "content": "We call these specialised version of RA operations RelOps.\n One major task of the query processor:\n given a set of RA operations to be executed\n find a combination of RelOps to do this efficiently\n Requires the query translator/optimiser to consider\n information about relations (e.g. sizes, primary keys, ...)\n information about operations (e.g. selection reduces size)\n RelOps are realised at execution time\n as a collection of inter-communicating nodes\n communicating either via pipelines or temporary relations\n",
  "key_words": [
   "query",
   "evaluation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Terminology Variations\n",
  "content": "Relational algebra expression of SQL query\n intermediate query representation\n logical query plan\n Execution plan as collection of RelOps\n query evaluation plan\n query execution plan\n physical query plan\n Representation of RA operators and expressions\n \u03c3 = Select = Sel, \u00a0\u00a0\u00a0 \u03c0 = Project = Proj\n R \u22c8 S = R Join S = Join(R,S), \u00a0\u00a0\u00a0 \u2227 = &, \u00a0\u00a0\u00a0 \u2228 = |\n",
  "key_words": [
   "terminology",
   "variation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Query Translation\n",
  "content": "Query translation: \u00a0 SQL statement text \u2192 RA expression\n",
  "key_words": [
   "query",
   "translation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Query Translation\n",
  "content": "Translation step: \u00a0 SQL text \u2192 RA expression\n Example:\n SQL: select name from Students where id=7654321; -- is translated to RA:  Proj[name](Sel[id=7654321]Students) Processes: \u00a0lexer/parser, \u00a0mapping rules, \u00a0rewriting rules.\n Mapping from SQL to RA may include some optimisations, e.g.\n  select * from Students where id = 54321 and age > 50; -- is translated to Sel[age>50](Sel[id=54321]Students) -- rather than ... because of index on id Sel[id=54321&age>50](Students)",
  "key_words": [
   "query",
   "translation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Parsing SQL\n",
  "content": "Parsing task is similar to that for programming languages.\n Language elements:\n keywords: \u00a0 create, \u00a0 select, \u00a0 from, \u00a0 where, \u00a0 ...\n identifiers: \u00a0 Students, \u00a0 name, \u00a0 id, \u00a0 CourseCode, \u00a0 ...\n operators: \u00a0 +, \u00a0 -, \u00a0 =, \u00a0 <, \u00a0 >, \u00a0 AND, \u00a0 OR, \u00a0 NOT, \u00a0 IN, \u00a0 ...\n constants: \u00a0 'abc', \u00a0 123, \u00a0 3.1, \u00a0 '01-jan-1970', \u00a0 ...\n PostgreSQL parser ...\n implemented via lex/yacc \u00a0 (src/backend/parser)\n maps all identifiers to lower-case \u00a0 (A-Z \u2192 a-z)\n needs to handle user-extendable operator set\n makes extensive use of catalog \u00a0 (src/backend/catalog)\n",
  "key_words": [
   "parsing",
   "sql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping SQL to Relational Algebra\n",
  "content": "A given SQL query typically has many translations to RA.\n For example:\n SELECT s.name, e.subj FROM   Students s, Enrolments e WHERE  s.id = e.sid AND e.mark < 50; is equivalent to any of\n \u03c0s.name,e.subj( \u03c3s.id=e.sid \u2227 e.mark<50 ( Students \u00d7 Enrolments ) )\n \u03c0s.name,e.subj( \u03c3s.id=e.sid ( \u03c3e.mark<50 ( Students \u00d7 Enrolments ) ) )\n \u03c0s.name,e.subj( \u03c3e.mark<50 ( Students \u22c8s.id=e.sid Enrolments ) ) )\n \u03c0s.name,e.subj( Students \u22c8s.id=e.sid ( \u03c3e.mark<50 ( Enrolments ) ) )\n",
  "key_words": [
   "mapping",
   "sql",
   "to",
   "relational",
   "algebra"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping SQL to Relational Algebra\n",
  "content": "More complex example:\n select   distinct s.code from     Course c, Subject s, Enrolment e where    c.id = e.course and c.subject = s.id group by s.id  having count(*) > 100; can be translated to the relational algebra expression\n Uniq(Proj[code](     GroupSelect[groupSize>100](         GroupBy[s.id] (             Enrolment \u22c8 Course \u22c8 Subjects ))))",
  "key_words": [
   "mapping",
   "sql",
   "to",
   "relational",
   "algebra"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping SQL to Relational Algebra\n",
  "content": "The join operations could be done in two different ways:\n Note: for a join on n tables, there are potentially O(n!) possible trees\n The query optimiser aims to find version with lowest total cost.\n",
  "key_words": [
   "mapping",
   "sql",
   "to",
   "relational",
   "algebra"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping Rules\n",
  "content": "Mapping from SQL \u2192 RA expression requires:\n a collection of templates, \u22651 for each kind of query\n a process to match an SQL statement to a template\n mapping rules for translating matched query into RA\n May need to apply >1 templates to map whole SQL statement.\n After mapping, apply rewriting rules to \"improve\" RA expression\n convert to equivalent, simpler, more efficient expression\n  Note: PostgreSQL also has user-defined mapping rules (CREATE RULE)\n",
  "key_words": [
   "mapping",
   "rule"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping Rules\n",
  "content": "Projection:\n SELECT \u00a0 a+b\u00a0AS\u00a0x, c\u00a0AS\u00a0y \u00a0 FROM \u00a0 R ... \u21d2 \u00a0\u00a0 Proj[x\u2190a+b, y\u2190c](R)\n SQL projection extends RA projection with renaming and assignment\n Join:\n SELECT ... FROM ... R, S ... WHERE ... R.f \u00a0op\u00a0 S.g ... , \u00a0\u00a0 or\n SELECT ... FROM ... R\u00a0JOIN\u00a0S ON \u00a0(R.f\u00a0op\u00a0S.g) ... WHERE ...\n \u21d2 \u00a0\u00a0 Join[R.f op S.g ](R,S)\n",
  "key_words": [
   "mapping",
   "rule"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Mapping Rules\n",
  "content": "Selection:\n SELECT \u00a0 ... \u00a0 FROM \u00a0 ... R ... \u00a0 WHERE \u00a0... R.f \u00a0op\u00a0 val ...\n \u21d2 \u00a0\u00a0 Select[R.f op val](R)\n SELECT \u00a0 ... \u00a0 FROM \u00a0 ... R ... \u00a0 WHERE \u00a0... Cond1,R \u00a0AND\u00a0 Cond2,R ...\n \u21d2 \u00a0\u00a0 Select[Cond1,R & Cond2,R](R)  or  \u21d2 \u00a0\u00a0 Select[Cond1,R](Select[Cond2,R](R))\n",
  "key_words": [
   "mapping",
   "rule"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 13: Mapping OR expressions\n",
  "content": "Possible mappings for WHERE expressions with AND are\n SELECT \u00a0 ... \u00a0 FROM \u00a0 ... R ... \u00a0 WHERE \u00a0... X AND Y ...\n \u21d2 \u00a0\u00a0 Select[X & Y](R) \u00a0\u00a0 or \u00a0\u00a0 Select[X](Select[Y](R))\n What are possible mappings for\n SELECT \u00a0 ... \u00a0 FROM \u00a0 ... R ... \u00a0 WHERE \u00a0... X OR Y ...\n Use these to translate:\n select * from R where (a=1 or a=3) and b < c",
  "key_words": [
   "exercise",
   "13",
   "mapping",
   "or",
   "expression"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Mapping Rules\n",
  "content": "Aggregation operators (e.g. MAX, SUM, ...):\n add as new operators in extended RA  e.g. SELECT MAX(age) FROM ... \u00a0\u00a0 \u21d2 \u00a0\u00a0 max(Proj[age](...))\n Sorting (ORDER BY):\n add Sort operator into extended RA \u00a0 (e.g. Sort[+name,-age](...))\n Duplicate elimination (DISTINCT):\n add Uniq operator into extended RA \u00a0 (e.g. Uniq(Proj(...)))\n Grouping (GROUP BY, HAVING):\n add operators into extended RA \u00a0 (e.g. GroupBy, GroupSelect )\n",
  "key_words": [
   "mapping",
   "rule"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Mapping Rules\n",
  "content": "View example: assuming Employee(id,name,birthdate,salary)\n -- view definition create view OldEmps as select * from Employees where  birthdate < '01-01-1960'; -- view usage select name from OldEmps; yields\n OldEmps \u00a0=\u00a0 Select[birthdate<'01-01-1960'](Employees)\n Projname(OldEmps)  \u21d2 \u00a0\u00a0 Projname(Select[birthdate<'01-01-1960'](Employees))\n",
  "key_words": [
   "mapping",
   "rule"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 14: Mapping Views\n",
  "content": "Given the following definitions:\n create table R(a integer, b integer, c integer);  create view RR(f,g,h) as select * from R where a > 5 and b = c; Show how the following might be mapped to RA:\n select * from RR where f > 10; Produced: 6 Sep 2018\n",
  "key_words": [
   "exercise",
   "14",
   "mapping",
   "view"
  ],
  "question": null,
  "intent_tag": "exercise"
 }
]