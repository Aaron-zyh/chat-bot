[
 {
  "topic": "Week 2 Lectures",
  "content": "Catalogs\n",
  "key_words": [
   "week",
   "2",
   "lecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Catalogs 1/60\n",
  "content": "Catalogs are tables describing database objects, e.g.\n pg_class holds core information about tables\n relname, relnamespace, reltype, relowner, ...\n relkind, relnatts, relhaspkey, relacl[], ...\n pg_attribute contains information about attributes\n attrelid, attname, atttypid, attnum, ...\n pg_type contains information about types\n typname, typnamespace, typowner, typlen, ...\n typtype, typrelid, typinput, typoutput, ...\n",
  "key_words": [
   "catalog"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "PostgreSQL Catalog 2/60\n",
  "content": "You can explore the PostgreSQl catalog via psql commands\n \\d gives a list of all tables and views\n \\d Table gives a schema for Table\n \\df gives a list of user-defined functions\n \\df+ Function gives details of Function\n \\ef Function allows you to edit Function\n \\dv gives a list of user-defined views\n \\d+ View gives definition of View\n You can also explore via SQL on the catalog tables\n",
  "key_words": [
   "postgresql",
   "catalog"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 1: Table Statistics 3/60\n",
  "content": "Using the PostgreSQL catalog, write a PLpgSQL function\n to return table name and #tuples in table\n for all tables in the public schema\n create type TableInfo as (table text, ntuples int);\n create function pop() returns setof TableInfo ...\n Hints:\n table is a reserved word\n you will need to use dynamically-generated queries.\n",
  "key_words": [
   "exercise",
   "1",
   "table",
   "statistic"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Exercise 2: Extracting a Schema 4/60\n",
  "content": "Write a PLpgSQL function:\n function schema() returns setof text\n giving a list of table schemas in the public schema\n It should behave as follows:\n db=# select * from schema();\n             tables\n ---------------------------\n  table1(x, y, z)\n  table2(a, b)\n  table3(id, name, address)\n ...\n",
  "key_words": [
   "exercise",
   "2",
   "extracting",
   "a",
   "schema"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Exercise 3: Enumerated Types 5/60\n",
  "content": "PostgreSQL allows you to define enumerated types, e.g.\n create type Mood as enum ('sad', 'happy');\n Creates a type with two ordered values 'sad' < 'happy'\n What is created in the catalog for the above definition?\n Hint:\n pg_type(oid, typname, typelen, typetype, ...)\n pg_enum(oid, enumtypid, enumlabel)\n Storage Manager\n",
  "key_words": [
   "exercise",
   "3",
   "enumerated",
   "type"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "DBMS Storage Manager 7/60\n",
  "content": "Levels of DBMS related to storage management:\n",
  "key_words": [
   "dbms",
   "storage",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Storage Technology 8/60\n",
  "content": "Persistent storage is\n large, cheap, relatively slow, accessed in blocks\n used for long-term storage of data\n Computational storage is\n small, expensive, fast, accessed by byte/word\n used for all analysis of data\n Access cost HDD:RAM \u2245 100000:1, e.g.\n 100ms to read block containing two tuples\n 1\u00b5s to compare fields in two tuples\n",
  "key_words": [
   "storage",
   "technology"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Cost Models 9/60\n",
  "content": "Throughout this course, we compare costs of DB operations\n Important aspects in determining cost:\n data is always transferred to/from disk as whole blocks (pages)\n cost of manipulating tuples in memory is negligible\n overall cost determined primarily by #data-blocks read/written\n Complicating factors in determining costs:\n not all page accesses require disk access  (buffer pool)\n tuples typically have variable size  (tuples/page ?)\n More details later ...\n",
  "key_words": [
   "cost",
   "model"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "File Management 10/60\n",
  "content": "Aims of file management subsystem:\n organise layout of data within the filesystem\n handle mapping from database ID to file address\n transfer blocks of data between buffer pool and filesystem\n also attempts to handle file access error problems (retry)\n Builds higher-level operations on top of OS file operations.\n",
  "key_words": [
   "file",
   "management"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Management 11/60\n",
  "content": "Typical file operations provided by the operating system:\n fd = open(fileName,mode)\n   // open a named file for reading/writing/appending\n close(fd)\n   // close an open file, via its descriptor nread = read(fd, buf, nbytes)\n   // attempt to read data from file into buffer nwritten = write(fd, buf, nbytes)\n   // attempt to write data from buffer to file\n lseek(fd, offset, seek_type)\n   // move file pointer to relative/absolute file offset\n fsync(fd)\n   // flush contents of file buffers to disk\n",
  "key_words": [
   "file",
   "management"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "DBMS File Organisation 12/60\n",
  "content": " Different DBMSs make different choices, e.g.\n by-pass the file system and use a raw disk partition\n have a single very large file containing all DB data\n have several large files, with tables spread across them\n have multiple data files, one for each table\n have multiple files for each table\n etc.\n",
  "key_words": [
   "dbms",
   "file",
   "organisation"
  ],
  "question": [
   "How is data for DB objects arranged in the file system?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "Single-file DBMS 13/60\n",
  "content": "Consider a single file for the entire database (e.g. SQLite)\n Objects are allocated to regions (segments) of the file.\n If an object grows too large for allocated segment, allocate an extension.\n What happens to allocated space when objects are removed?\n",
  "key_words": [
   "single-file",
   "dbms"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file DBMS 14/60\n",
  "content": "Allocating space in Unix files is easy:\n simply seek to the place you want and write the data\n if nothing there already, data is appended to the file\n if something there already, it gets overwritten\n If the seek goes way beyond the end of the file:\n Unix does not (yet) allocate disk space for the \"hole\"\n allocates disk storage only when data is written there\n With the above, a disk/file manager is easy to implement.\n",
  "key_words": [
   "single-file",
   "dbms"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Single-file Disk Manager 15/60\n",
  "content": "Simple disk manager for a single-file database:\n // Disk Manager data/functions\n #define PAGESIZE 2048   // bytes per page\n typedef int PageID;     // PageID is block index\n typedef struct DBdescriptor {\n    char *dbname;     // copy of database name\n    int   fd;         // the database file\n    SpaceTable map;   // map of free/used areas    NameTable names;  // map names to areas + sizes\n    ...\n } *DB;\n typedef struct RelDescriptor {\n    char *relname;    // copy of table name\n    int   start;      // page index of start of table data\n    int   npages;     // number of pages of table data\n    ...\n } *Reln;\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file Disk Manager 16/60\n",
  "content": "// start using DB DB openDatabase(char *name) {    DB db = new(DBdescriptor);\n    db->dbname = strdup(name);\n    db->fd = open(name,O_RDWR);\n    db->map = readSpaceTable(db);\n    db->names = readNameTable(db);\n    return db;\n }\n // stop using DB and update all meta-data\n void closeDatabase(DB db) {\n    writeSpaceTable(db,db->map);\n    writeNameTable(db,db->names);\n    fsync(db->fd);  // ensure that changes reach disk\n    close(db->fd);\n    free(db);\n }\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file Disk Manager 17/60\n",
  "content": "// set up struct describing relation\n Reln openRelation(DB db, char *rname) {\n    Reln r = new(RelDescriptor);\n    r->relname = strdup(rname);\n    // get relation data from map tables\n    r->start = ...;\n    r->npages = ...;\n    return r;\n }\n // stop using a relation\n void closeRelation(Reln r) {\n    free(r);\n }\n #define nPages(r)  (r->npages)\n #define makePageID(r,i)  (r->first + i)\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file Disk Manager 18/60\n",
  "content": "// assume that Page = buffer of PageSize bytes\n // assume that PageID = block number in file\n // read page from file into memory buffer\n void get_page(DB db, PageID p, Page buf) {\n    lseek(db->fd, pageOffset(p), SEEK_SET);\n    read(db->fd, buf, PAGESIZE);\n }\n // write page from memory buffer to file\n void put_page(Db db, PageID p, Page buf) {\n    lseek(db->fd, pageOffset(p), SEEK_SET);\n    write(db->fd, buf, PAGESIZE);\n }\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file Disk Manager 19/60\n",
  "content": "The pageOffset() function uses the DB map\n takes a PageID value\n uses the DB space map\n returns an absolute file offset\n E.g. each table is allocated large contiguous segment of file\n get start address of relation(PageID) from map\n add pageNumber(PageID)*PAGESIZE to give offset\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Single-file Disk Manager 20/60\n",
  "content": "// managing contents of mapping table is complex\n // assume a list of (offset,length,status) tuples\n // allocate n new pages at end of file\n PageID allocate_pages(int n) {\n    int endfile = lseek(db->fd, 0, SEEK_END);\n    addNewEntry(db->map, endfile, n);\n    // note that file itself is not changed\n }\n // drop n pages starting from p\n void deallocate_pages(PageID p, int n) {\n    markUnused(db->map, p, n);\n    // note that file itself is not changed\n }\n",
  "key_words": [
   "single-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Example: Scanning a Relation 21/60\n",
  "content": "With the above disk manager, the query:\n select name from Employee\n might be implemented as something like\n DB db = openDatabase(\"myDB\");\n Reln r = openRelation(db,\"Employee\");\n Page buffer = malloc(PAGESIZE*sizeof(char));\n for (int i = 0; i < nPages(r); i++) {\n    PageID pid = makePageID(r,i);\n    get_page(db, pid, buffer);\n    foreach tuple in buffer {\n       get tuple data and extract name\n    }\n }\n",
  "key_words": [
   "example",
   "scanning",
   "a",
   "relation"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "Exercise 4: Relation Scan Cost 22/60\n",
  "content": "Consider a table R(x,y,z) with 105 tuples, implemented as\n number of tuples r = 100,000\n average size of tuples R = 200 bytes\n size of data pages B = 4096 bytes\n time to read one data page Tr = 10msec\n time to check one tuple 1 usec\n time to form one result tuple 1 usec\n time to write one result page Tr = 10msec\n Calculate the total time-cost for answering the query:\n select * from R where x > 10;\n if 50% of the tuples satisfy the condition.\n",
  "key_words": [
   "exercise",
   "4",
   "relation",
   "scan",
   "cost"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Multi-file Disk Manager 23/60\n",
  "content": "Using multiple files (one file per relation) can be easier\n E.g. extending the size of a relation\n",
  "key_words": [
   "multi-file",
   "disk",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "PostgreSQL Storage Manager 24/60\n",
  "content": "PostgreSQL uses the following file organisation ...\n",
  "key_words": [
   "postgresql",
   "storage",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL Storage Manager 25/60\n",
  "content": "Components of storage subsystem:\n mapping from relations to files   (RelFileNode)\n abstraction for open relation pool   (storage/smgr)\n functions for managing files   (storage/smgr/md.c)\n file-descriptor pool   (storage/file)\n PostgreSQL has two basic kinds of files:\n heap files containing data (tuples)\n index files containing index entries\n Note: smgr designed for many storage devices; only mag disk handler used\n",
  "key_words": [
   "postgresql",
   "storage",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Relations as Files 26/60\n",
  "content": "PostgreSQL identifies relation files via their OIDs.\n The core data structure for this is RelFileNode:\n typedef struct RelFileNode {\n     Oid  spcNode;  // tablespace\n     Oid  dbNode;   // database\n     Oid  relNode;  // relation\n } RelFileNode;\n Global (shared) tables (e.g. pg_database) have\n   spcNode == GLOBALTABLESPACE_OID\n   dbNode == 0\n",
  "key_words": [
   "relation",
   "a",
   "file"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Relations as Files 27/60\n",
  "content": "The relpath function maps RelFileNode to file:\n char *relpath(RelFileNode r)  // simplified\n {\n    char *path = malloc(ENOUGH_SPACE);\n    if (r.spcNode == GLOBALTABLESPACE_OID) {\n      /* Shared system relations live in PGDATA/global */\n      Assert(r.dbNode == 0);\n       sprintf(path, \"%s/global/%u\",\n               DataDir, r.relNode);\n    }\n    else if (r.spcNode == DEFAULTTABLESPACE_OID) {\n      /* The default tablespace is PGDATA/base */\n      sprintf(path, \"%s/base/%u/%u\",\n               DataDir, r.dbNode, r.relNode);\n    }\n    else {\n      /* All other tablespaces accessed via symlinks */\n      sprintf(path, \"%s/pg_tblspc/%u/%u/%u\", DataDir\n               r.spcNode, r.dbNode, r.relNode);\n    }\n    return path;\n }\n",
  "key_words": [
   "relation",
   "a",
   "file"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "File Descriptor Pool 28/60\n",
  "content": "Unix has limits on the number of concurrently open files.\n PostgreSQL maintains a pool of open file descriptors:\n to hide this limitation from higher level functions\n to minimise expensive open() operations\n File names are simply strings: typedef char *FileName\n Open files are referenced via: typedef int File\n A File is an index into a table of \"virtual file descriptors\".\n",
  "key_words": [
   "file",
   "descriptor",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Descriptor Pool 29/60\n",
  "content": "Interface to file descriptor (pool):\n File FileNameOpenFile(FileName fileName,\n                       int fileFlags, int fileMode);\n      // open a file in the database directory ($PGDATA/base/...)\n File OpenTemporaryFile(bool interXact);\n      // open temp file; flag: close at end of transaction?\n void FileClose(File file);\n void FileUnlink(File file);\n int  FileRead(File file, char *buffer, int amount);\n int  FileWrite(File file, char *buffer, int amount);\n int  FileSync(File file);\n long FileSeek(File file, long offset, int whence);\n int  FileTruncate(File file, long offset);\n Analogous to Unix syscalls open(), close(), read(), write(), lseek(), ...\n",
  "key_words": [
   "file",
   "descriptor",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Descriptor Pool 30/60\n",
  "content": "Virtual file descriptors (Vfd)\n physically stored in dynamically-allocated array\n also arranged into list by recency-of-use\n VfdCache[0] holds list head/tail pointers.\n",
  "key_words": [
   "file",
   "descriptor",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Descriptor Pool 31/60\n",
  "content": "Virtual file descriptor records (simplified):\n typedef struct vfd\n {\n     s_short  fd;              // current FD, or VFD_CLOSED if none\n     u_short  fdstate;         // bitflags for VFD's state\n     File     nextFree;        // link to next free VFD, if in freelist\n     File     lruMoreRecently; // doubly linked recency-of-use list\n     File     lruLessRecently;\n     long     seekPos;         // current logical file position\n     char     *fileName;       // name of file, or NULL for unused VFD\n     // NB: fileName is malloc'd, and must be free'd when closing the VFD\n     int      fileFlags;       // open(2) flags for (re)opening the file\n     int      fileMode;        // mode to pass to open(2)\n } Vfd;\n",
  "key_words": [
   "file",
   "descriptor",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "File Manager 32/60\n",
  "content": "Reminder: PostgreSQL file organisation",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 33/60\n",
  "content": "PostgreSQL stores each table\n in the directory PGDATA/pg_database.oid\n often in multiple files (aka forks)\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 34/60\n",
  "content": "Data files   (Oid, Oid.1, ...):\n sequence of fixed-size blocks/pages  (typically 8KB)\n each page contains tuple data and admin data  (see later)\n max size of data files 1GB  (Unix limitation)\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 35/60\n",
  "content": "Free space map   (Oid_fsm):\n indicates where free space is in data pages\n \"free\" space is only free after VACUUM   (DELETE simply marks tuples as no longer in use xmax)\n Visibility map   (Oid_vm):\n indicates pages where all tuples are \"visible\"   (visible = accessible to all currently active transactions)\n such pages can be ignored by VACUUM\n also used for index pages, to indicate all index entries visible   (allows index-only scans to be done more efficiently)\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 36/60\n",
  "content": "Relation files are identified via pg_class.relfilenode\n most of the time, this is the same as pg_class.oid\n and with forkNum appended, unless it is zero\n The core data structure for this is RelFileNode:\n typedef struct RelFileNode {\n     Oid  spcNode;  // tablespace\n     Oid  dbNode;   // database\n     Oid  relNode;  // relation\n } RelFileNode;\n Some relations have no relfilenode; use pg_filenode.map file\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 37/60\n",
  "content": "The \"magnetic disk storage manager\" (storage/smgr/md.c)\n manages its own pool of open file descriptors (Vfd's)\n may use several Vfd's to access data, if several forks\n manages mapping from PageID to file+offset.\n PostgreSQL PageID values are structured:\n typedef struct\n {\n     RelFileNode rnode;    // which relation/file\n     ForkNumber  forkNum;  // which fork (of reln)\n     BlockNumber blockNum; // which page/block } BufferTag;\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 38/60\n",
  "content": "Access to a block of data proceeds (roughly) as follows:\n // pageID set from pg_catalog tables\n // buffer obtained from Buffer pool\n getBlock(BufferTag pageID, Buffer buf)\n {\n    Vfd vf;  off_t offset;\n    (vf, offset) = findBlock(pageID)\n    lseek(vf.fd, offset, SEEK_SET)\n    vf.seekPos = offset;\n    nread = read(vf.fd, buf, BLOCKSIZE)\n    if (nread < BLOCKSIZE) ... we have a problem\n }\n BLOCKSIZE is a global configurable constant (default: 8192)\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... File Manager 39/60\n",
  "content": "findBlock(BufferTag pageID) returns (Vfd, off_t)\n {\n    offset = pageID.BlockNumber * BLOCKSIZE\n    fileID = relpath(pageID.rnode)\n    if (pageID.forkNum > 0)\n       fileID = fileID+\".\"+pageID.ForkNum\n    if (fileID is not in Vfd pool)\n       fd = allocate new Vfd for this fileID\n    else\n       fd = use Vfd from pool\n    if (offset > fd.fileSize) {\n       fd = allocate new Vfd for next fork\n       offset = offset - fd.fileSize\n    }\n    return (fd, offset)\n }\n",
  "key_words": [
   "file",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "DBMS Parameters 40/60\n",
  "content": "Our view of relations in DBMSs:\n a relation is a set of r  tuples, with average size R  bytes\n the tuples are stored in b  data pages on disk\n each page has size B  bytes and contains up to c  tuples\n data is transferred disk\u2194memory in whole pages\n cost of disk\u2194memory transfer Tr , Tw  dominates other costs\n",
  "key_words": [
   "dbms",
   "parameter"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... DBMS Parameters 41/60\n",
  "content": "Typical DBMS/table parameter values:\n Quantity Symbol E.g. Value\n total # tuples r 106\n record size R 128 bytes\n total # pages b 105\n page size B 8192 bytes\n # tuples per page c 60\n page read/write time Tr ,Tw 10 msec\n cost to process\n one page in memory\n - \u2245 0\n Buffer Pool\n",
  "key_words": [
   "dbms",
   "parameter"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Buffer Pool 43/60\n",
  "content": "Aim of buffer pool:\n hold pages read from database files, for possible re-use\n Buffer pool operations:   (both take single PageID argument)\n request_page(pid),   release_page(pid), ...\n Buffer pool data structures:\n Page frames[NBUFS];   FrameData directory[NBUFS];\n Page is byte[BUFSIZE],   FrameData is struct {...}\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 44/60\n",
  "content": "",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 45/60\n",
  "content": "For each frame, we need to know:   (FrameData)\n which Page it contains, or whether empty/free\n whether it has been modified since loading (dirty bit)\n how many transactions are currently using it (pin count)\n time-stamp for most recent access (assists with replacement)\n which page = PageID = (RelationID,PageNum)    (note: Page = Block)\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 46/60\n",
  "content": " Buffer buf;\n int N = numberOfBlocks(Rel);\n for (i = 0; i < N; i++) {\n    pageID = makePageID(db,Rel,i);\n    getBlock(pageID, buf);\n    for (j = 0; j < nTuples(buf); j++)\n       process(buf, j)\n }\n Requires N page reads.\n If we read it again, N page reads.\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": [
   "How scans are performed without Buffer Pool?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 47/60\n",
  "content": " Buffer buf;\n int N = numberOfBlocks(Rel);\n for (i = 0; i < N; i++) {\n    pageID = makePageID(db,Rel,i);\n    bufID = request_page(pageID);\n    buf = frames[bufID]\n    for (j = 0; j < nTuples(buf); j++)\n       process(buf, j)\n    release_page(pageID);\n }\n Requires N page reads on the first pass.\n If we read it again, 0 \u2264 page reads \u2264 N\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": [
   "How scans are performed with Buffer Pool?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 48/60\n",
  "content": "Implementation of request_page()\n int request_page(PageID pid)\n {\n    if (pid in Pool)\n       bufID = index for pid in Pool\n    else {\n       if (no free frames in Pool)\n          evict a page (free a frame)\n       bufID = allocate free frame\n       directory[bufID].page = pid\n       directory[bufID].pin_count = 0\n       directory[bufID].dirty_bit = 0\n    }\n    directory[bufID].pin_count++\n    return bufID\n }\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 49/60\n",
  "content": "Implementation of release_page()\n int release_page(PageID pid)\n {\n    bufID = index for pid in Pool\n    directory[bufID].pin_count--\n }\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Buffer Pool 50/60\n",
  "content": "Evicting a page ...\n find frame(s) preferably satisfying\n pin count = 0   (i.e. nobody using it)\n dirty bit = 0   (not modified)\n if selected frame was modified, flush frame to disk\n flag directory entry as \"frame empty\"\n If multiple frames can potentially be released\n need a policy to decide which is best choice\n",
  "key_words": [
   "buffer",
   "pool"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Page Replacement Policies 51/60\n",
  "content": "Several schemes are commonly in use:\n Least Recently Used (LRU)\n Most Recently Used (MRU)\n First in First Out (FIFO)\n Random\n LRU / MRU require knowledge of when pages were last accessed\n how to keep track of \"last access\" time?\n base on request/release ops or on real page usage?\n",
  "key_words": [
   "page",
   "replacement",
   "policy"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Page Replacement Policies 52/60\n",
  "content": "Cost benefit from buffer pool (with n frames) is determined by:\n number of available frames (more \u21d2 better)\n replacement strategy vs page access pattern\n Example (a): sequential scan, LRU or MRU, n \u2265 b\n First scan costs b reads; subsequent scans are \"free\".\n Example (b): sequential scan, MRU, n < b\n First scan costs b reads; subsequent scans cost b - n reads.\n Example (c): sequential scan, LRU, n < b\n All scans cost b reads; known as sequential flooding.\n",
  "key_words": [
   "page",
   "replacement",
   "policy"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Effect of Buffer Management 53/60\n",
  "content": "Consider a query to find customers who are also employees:\n select c.name\n from   Customer c, Employee e\n where  c.ssn = e.ssn;\n This might be implemented inside the DBMS via nested loops:\n for each tuple t1 in Customer {\n     for each tuple t2 in Employee {\n         if (t1.ssn == t2.ssn)\n             append (t1.name) to result set\n     }\n }\n",
  "key_words": [
   "effect",
   "of",
   "buffer",
   "management"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Effect of Buffer Management 54/60\n",
  "content": "In terms of page-level operations, the algorithm looks like:\n Rel rC = openRelation(\"Customer\");\n Rel rE = openRelation(\"Employee\");\n for (int i = 0; i < nPages(rC); i++) {\n     PageID pid1 = makePageID(db,rC,i);\n     Page p1 = request_page(pid1);\n     for (int j = 0; j < nPages(rE); j++) {\n         PageID pid2 = makePageID(db,rE,j);\n         Page p2 = request_page(pid2);\n         // compare all pairs of tuples from p1,p2\n         // construct solution set from matching pairs\n         release_page(pid2);\n     }\n     release_page(pid1);\n }\n",
  "key_words": [
   "effect",
   "of",
   "buffer",
   "management"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 5: Buffer Management Cost Benefit (i) 55/60\n",
  "content": "Assume that:\n the Customer relation has bC pages (e.g. 5)\n the Employee relation has bE pages (e.g. 4)\n Compute how many page reads occur ...\n if we have only 2 buffers (i.e. effectively no buffer pool)\n when a buffer pool with MRU replacement strategy is used\n when a buffer pool with LRU replacement strategy is used\n For the last two, buffer pool has n=3 slots (n < bC and n < bE)\n",
  "key_words": [
   "exercise",
   "5",
   "buffer",
   "management",
   "cost",
   "benefit",
   "(i)"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Exercise 6: Buffer Management Cost Benefit (ii) 56/60\n",
  "content": "If the tables were larger, the above analysis would be tedious.\n Write a C program to simulate buffer pool usage\n assuming a nested loop join as above\n argv[1] gives number of pages in \"outer\" table\n argv[2] gives number of pages in \"inner\" table\n argv[3] gives number of slots in buffer pool\n argv[4] gives replacement strategy (LRU,MRU,FIFO-Q)\n",
  "key_words": [
   "exercise",
   "6",
   "buffer",
   "management",
   "cost",
   "benefit",
   "(ii)"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "PostgreSQL Buffer Manager 57/60\n",
  "content": "PostgreSQL buffer manager:\n provides a shared pool of memory buffers for all backends\n all access methods get data from disk via buffer manager\n Buffers are located in a large region of shared memory.\n Definitions:  src/include/storage/buf*.h\n Functions:  src/backend/storage/buffer/*.c\n Buffer code is also used by backends who want a private buffer pool\n",
  "key_words": [
   "postgresql",
   "buffer",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL Buffer Manager 58/60\n",
  "content": "Buffer pool consists of:\n BufferDescriptors\n shared fixed array (size NBuffers) of BufferDesc\n BufferBlocks\n shared fixed array (size NBuffers) of 8KB frames\n Buffer = index values in above arrays\n indexes: global buffers 1..NBuffers; local buffers negative\n Size of buffer pool is set in postgresql.conf, e.g.\n shared_buffers = 16MB   # min 128KB, 16*8KB buffers\n",
  "key_words": [
   "postgresql",
   "buffer",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL Buffer Manager 59/60\n",
  "content": "",
  "key_words": [
   "postgresql",
   "buffer",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL Buffer Manager 60/60\n",
  "content": "include/storage/buf.h\n basic buffer manager data types (e.g. Buffer)\n include/storage/bufmgr.h\n definitions for buffer manager function interface (i.e. functions that other parts of the system call to use buffer manager)\n include/storage/buf_internals.h\n definitions for buffer manager internals (e.g. BufferDesc)\n Code: backend/storage/buffer/*.c\n Commentary: backend/storage/buffer/README\n Produced: 2 Aug 2018\n",
  "key_words": [
   "postgresql",
   "buffer",
   "manager"
  ],
  "question": null,
  "intent_tag": "unknow"
 }
]