[
 {
  "topic": "Week 10 Lectures",
  "content": "Beyond RDBMSs.",
  "key_words": [
   "week",
   "10",
   "lecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Future of Database 2/52\n",
  "content": "Core \"database\" goals:\n deal with very large amounts of data (terabytes, petabyes, ...)\n very-high-level languages (deal with big data in uniform ways)\n query execution   (if evaluation too slow \u21d2 useless)\n At the moment (and for the last 20 years) RDBMSs dominate ...\n simple/clean data model, backed up by theory\n high-level language for accessing data\n 40 years development work on RDBMS engine technology\n RDBMSs work well in domains with uniform, structured data.\n",
  "key_words": [
   "future",
   "of",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Future of Database 3/52\n",
  "content": "Limitations/pitfalls of RDBMSs:\n NULL is ambiguous: unknown, not applicable, not supplied\n \"limited\" support for constraints/integrity and rules\n no support for uncertainty (data represents the state-of-the-world)\n data model too simple (e.g. no direct support for complex objects)\n query model too rigid (e.g. no approximate matching)\n continually changing data sources not well-handled\n data must be \"molded\" to fit a single rigid schema\n database systems must be manually \"tuned\"\n do not scale well to some data sets (e.g. Google, Telco's)\n",
  "key_words": [
   "future",
   "of",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Future of Database 4/52\n",
  "content": " Extend the relational model ...\n add new data types and query ops for new applications deal with uncertainty/inaccuracy/approximation in data\n Replace the relational model ...\n object-oriented DBMS ... OO programming with persistent objects\n XML DBMS ... all data stored as XML documents, new query model\n application-effective data model (e.g. (key,value) pairs)\n Performance ...\n new query algorithms/data-structures for new types of queries\n DBMSs that \"tune\" themselves\n",
  "key_words": [
   "future",
   "of",
   "database"
  ],
  "question": [
   "How to overcome (some of) these limitations?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "... Future of Database 5/52\n",
  "content": "An overview of the possibilities:\n \"classical\" RDBMS   (e.g. PostgreSQL, Oracle, SQLite)\n parallel DBMS   (e.g. XPRS)\n distributed DBMS   (e.g. Cohera)\n deductive databases   (e.g. Datalog)\n temporal databases   (e.g. MariaDB)\n column stores   (e.g. C-Store?)\n object-oriented DBMS   (e.g. ObjectStore)\n key-value stores   (e.g. Redis, DynamoDB)\n wide column stores   (e.g. Cassandra, Scylla, HBase)\n graph databases   (e.g. Neo4J, Datastax)\n document stores   (e.g. MongoDB, Couchbase)\n search engines   (e.g. Google, Solr)\n",
  "key_words": [
   "future",
   "of",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Big Data 7/52\n",
  "content": "Some modern applications have massive data sets (e.g. Google)\n far too large to store on a single machine/RDBMS\n query demands far too high even if could store in DBMS\n Approach to dealing with such data\n distribute data over large collection of nodes  (also, redundancy)\n provide computational mechanisms for distributing computation\n Often this data does not need full relational selection\n represent data via (key,value) pairs\n unique keys can be used for addressing data\n values can be large objects (e.g. web pages, images, ...)\n",
  "key_words": [
   "big",
   "data"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Big Data 8/52\n",
  "content": "Popular computational approach to Big Data: map/reduce\n suitable for widely-distributed, very-large data\n allows parallel computation on such data to be easily specified\n distribute (map) parts of computation across network\n compute in parallel (possibly with further mapping)\n merge (reduce) multiple results for delivery to requestor\n Some Big Data proponents see no future need for SQL/relational ...\n depends on application (e.g. hard integrity vs eventual consistency)\n Humour: Parody of noSQL fans   (strong language warning)\n",
  "key_words": [
   "big",
   "data"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Information Retrieval 9/52\n",
  "content": "DBMSs generally do precise matching (although like/regexps)\n Information retrieval systems do approximate matching.\n E.g. documents containing these words (Google, etc.)\n Also introduces notion of \"quality\" of matching (e.g. tuple T1 is a better match than tuple T2)\n Quality also implies ranking of results.\n Much activity in incorporating IR ideas into DBMS context.\n Goal: support database exploration better.\n",
  "key_words": [
   "information",
   "retrieval"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Multimedia Data 10/52\n",
  "content": "Data which does not fit the \"tabular model\":\n image, video, music, text, ... (and combinations of these)\n Research problems:\n how to specify queries on such data? (image1 \u2245 image2)\n how to \"display\" results? (synchronize components)\n Solutions to the first problem typically:\n extend notions of \"matching\"/indexes for querying\n require sophisticated methods for capturing data features\n Sample query: find other songs like this one?\n",
  "key_words": [
   "multimedia",
   "data"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Uncertainty 11/52\n",
  "content": "Multimedia/IR introduces approximate matching.\n In some contexts, we have approximate/uncertain data.\n E.g. witness statements in a crime-fighting database\n http://www.youtube.com/watch?v=b2F-DItXtZs\n \"I think the getaway car was red ... or maybe orange ...\"\n \"I am 75% sure that John carried out the crime\"\n Work by Jennifer Widom at Stanford on the Trio system\n extends the relational model (ULDB)\n extends the query language (TriQL)\n",
  "key_words": [
   "uncertainty"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Stream Management Systems 12/52\n",
  "content": "Makes one addition to the relational model\n stream = infinite sequence of tuples, arriving one-at-a-time\n Applications: news feeds, telecomms, monitoring web usage, ...\n RDBMSs: run a variety of queries on (relatively) fixed data StreamDBs: run fixed queries on changing data (stream)\n Approaches:\n window = relation formed from a stream via a rule\n stream data type = build new stream-specific operations\n",
  "key_words": [
   "stream",
   "management",
   "system"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Graph Data 13/52\n",
  "content": "Uses graphs rather than tables as basic data structure tool.\n Applications: complex data representation, via \"flexible\" objects, e.g. XML\n Graph nature of data changes query model considerably.\n (e.g. Xquery language, high-level like SQL, but different operators, etc.)\n Implementing graphs in RDBMSs is often inefficient.\n Research problem: query processing for XML data.\n",
  "key_words": [
   "graph",
   "data"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Dispersed Databases 14/52\n",
  "content": "Characteristics of dispersed databases:\n very large numbers of small processing nodes\n data is distributed/shared among nodes\n Applications: environmental monitoring devices, \"intelligent dust\", ...\n Research issues:\n query/search strategies (how to organise query processing)\n distribution of data (trade-off between centralised and diffused)\n Less extreme versions of this already exist:\n grid and cloud computing\n database management for mobile devices\n Parallelism in Databases\n",
  "key_words": [
   "dispersed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Parallel DBMSs 16/52\n",
  "content": "The discussion so far has revolved around systems\n with a single or small number of processors\n accessing a single memory space\n getting data from one or more disk devices\n",
  "key_words": [
   "parallel",
   "dbms"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallel DBMSs 17/52\n",
  "content": "Throughput!",
  "key_words": [
   "parallel",
   "dbms"
  ],
  "question": [
   "Why parallelism?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallel DBMSs 18/52\n",
  "content": "DBMSs lend are a success story in application of parallelism\n can process many data elements (tuples) at the same time\n can create pipelines of query evaluation steps\n don't require special hardware\n can hide paralleism within the query evaluator\n application programmers don't need to change habits\n Compare this with effort to do parallel programming.\n",
  "key_words": [
   "parallel",
   "dbms"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Parallel Architectures 19/52\n",
  "content": "Types:   shared memory,   shared disk,   shared nothing\n Example shared-nothing architecture:\n Typically same room/LAN   (data transfer cost ~ 100's of \u03bcsecs .. msecs)\n",
  "key_words": [
   "parallel",
   "architecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Distributed Architectures 20/52\n",
  "content": "Distributed architectures are ...\n effectively shared-nothing, on a global-scale network\n Typically on the Internet   (data transfer cost ~ secs)\n",
  "key_words": [
   "distributed",
   "architecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Parallel Databases (PDBs) 21/52\n",
  "content": "Parallel databases provide various forms of parallelism ...\n process parallelism can speed up query evaluation\n processor parallelism can assist in speeding up memory ops\n processor parallelism introduces cache coherence issues\n disk parallelism can assist in overcoming latency\n disk parallelism can be used to improve fault-tolerance (RAID)\n one limiting factor is congestion on communication bus\n",
  "key_words": [
   "parallel",
   "database",
   "(pdbs)"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallel Databases (PDBs) 22/52\n",
  "content": "Types of parallelism\n pipeline parallelism\n multi-step process,   each processor handles one step\n run in parallel and pipeline result from one to another\n partition parallelism\n many processors running in parallel\n each performs same task on a subset of the data\n results from processors need to be merged\n",
  "key_words": [
   "parallel",
   "database",
   "(pdbs)"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Data Storage in PDBs 23/52\n",
  "content": "Consider each table as a collection of pages ...\n Page addressing on single processor/disk: (Table, File, Page)\n Table maps to a set of files (e.g. named by tableID)\n File distinguishes primary/overflow files\n PageNum maps to an offset in a specific file\n If multiple nodes, then addressing depends how data distributed\n partitioned: (Node, Table, File, Page)\n replicated: ({Nodes}, Table, File, Page)\n",
  "key_words": [
   "data",
   "storage",
   "in",
   "pdbs"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Data Storage in PDBs 24/52\n",
  "content": "Assume that each table/relation consists of pages in a file\n Can distribute data across multiple storage devices\n duplicate all pages from a relation  (replication)\n store some pages on one store, some on others  (partitioning)\n",
  "key_words": [
   "data",
   "storage",
   "in",
   "pdbs"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Data Storage in PDBs 26/52\n",
  "content": "Assume that partitioning is based on one attribute\n Data-partitioning strategies for one table on n nodes:\n round-robin,   hash-based,   range-based\n Round-robin partitioning\n cycle through nodes, new tuple added on \"next\" node\n e.g. i th tuple is placed on (i mod n)th node\n balances load on nodes;   no help for querying\n",
  "key_words": [
   "data",
   "storage",
   "in",
   "pdbs"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Data Storage in PDBs 27/52\n",
  "content": "Hash partitioning\n use hash value to determine which node and page\n e.g. i = hash(tuple) so tuple is placed on i th node\n helpful for equality-based queries ?   not really\n Range partitioning\n ranges of attr values are assigned to processors\n e.g. values 1-10 on node0,  11-20 on node1, ...,  99-100 noden-1\n potentially helpful for range-based queries\n In both cases, data skew may lead to unbalanced load\n",
  "key_words": [
   "data",
   "storage",
   "in",
   "pdbs"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Parallelism in DB Operations 28/52\n",
  "content": "Different types of parallelism in DBMS operations\n intra-operator parallelism\n get all machines working to compute a given operation\n (scan, sort, join)\n inter-operator parallelism\n each operator runs concurrently on a different processor (exploits pipelining)\n Inter-query parallelism\n different queries run on different processors\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallelism in DB Operations 29/52\n",
  "content": "Parallel scanning\n scan partitions in parallel and merge results\n selection may allow us to ignore some partitions (e.g. for range and hash partitioning)\n can build indexes on each partition\n Effectiveness depends on query type vs partitioning type\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallelism in DB Operations 30/52\n",
  "content": "Parallel sorting\n scan in parallel, range-partition during scan\n pipeline into local sort on each processor\n \"merge\" sorted partitions in order\n Potential problem:\n data skew because of unfortunate choice of partition points\n resolve by initial data sampling to determine partitions\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallelism in DB Operations 32/52\n",
  "content": "Parallel nested loop join\n each outer tuple needs to examine each inner tuple\n but only if it could potentially join\n range/hash partitioning reduce partitions to consider\n Parallel sort-merge join\n as noted above, parallel sort gives range partitioning\n merging partitioned tables has no parallelism (but is fast)\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallelism in DB Operations 35/52\n",
  "content": "Parallel hash join\n distribute partitions to different processors\n partition 0 of R goes to same site as partition 0 of S\n join phase can be done in parallel on each processor\n then results need to be merged\n very effective for equijoin\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Parallelism in DB Operations 36/52\n",
  "content": "Parallel hash join:\n",
  "key_words": [
   "parallelism",
   "in",
   "db",
   "operation"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "PostgreSQL and Parallelism 37/52\n",
  "content": "PostgreSQL assumes\n shared memory space accessable to all back-ends\n files for one table are located on one disk\n PostgreSQL allows\n data to be distributed across multiple disk devices\n So could run on ...\n shared-memory, shared-disk architectures\n hierarchical architectures with distributed virtual memory\n",
  "key_words": [
   "postgresql",
   "and",
   "parallelism"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL and Parallelism 38/52\n",
  "content": "PostgreSQL can provide\n multiple servers running on separate nodes\n application #1: high availability\n \"standby\" server takes over if primary server fails\n application #2: load balancing\n several servers can be used to provide same data\n direct queries to least loaded server\n Both need data synchronisation between servers\n PostgreSQL uses notion of master and slave servers.\n",
  "key_words": [
   "postgresql",
   "and",
   "parallelism"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... PostgreSQL and Parallelism 39/52\n",
  "content": "High availability ...\n updates occur on master, recorded in tx log\n tx logs shipped/streamed from master to slave(s)\n slave uses tx logs to maintain current state\n configuration controls frequency of log shipping\n bringing slave up-to-date is \"fast\" (~1-2secs)\n Note: small window for data loss (committed tx log records not sent)\n Load balancing ...\n not provided built-in to PostgreSQL, 3rd-party tools exist\n Distributed Databases\n",
  "key_words": [
   "postgresql",
   "and",
   "parallelism"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Distributed Databases 41/52\n",
  "content": "A distributed database (DDB) is\n collection of multiple logically-related databases\n distributed over a network (generally a WAN)\n A distributed database management system (DDBMS) is\n software that manages a distributed database\n providing access that hides complexity of distribution\n A DDBMS may involve\n instances of a single DBMS  (e.g. \u22651 PostgreSQL servers)\n a layer over multiple different DBMSs  (e.g. Oracle+PostgreSQL+DB2)\n",
  "key_words": [
   "distributed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Distributed Databases 44/52\n",
  "content": "Two kinds of distributed databases\n parallel database on a distributed architecture\n single schema, homogeneous DBMSs\n independent databases on a distributed architecture\n independent schemas, heterogeneous DBMSs\n The latter are also called federated databases\n Ultimately, the distributed database (DDB) provides\n global schema, with mappings from constituent schemas\n giving the impression of a single database\n",
  "key_words": [
   "distributed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Distributed Databases 45/52\n",
  "content": "Advantages of distributed databases\n allow information from multiple DBs to be merged\n provide for replication of some data  (resilience)\n allow for possible parallel query evaluation\n Disadavtanges of distributed databases\n cost of mapping between different schemas  (federated)\n communication costs  (write-to-network vs write-to-disk)\n maintaining ACID properties in distributed transactions\n",
  "key_words": [
   "distributed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Distributed Databases 46/52\n",
  "content": "Application examples:\n bank with multiple branches\n local branch-related data (e.g. accounts) stored in branch\n corporate data (e.g. HR) stored on central server(s)\n central register of credit-worthiness for customers\n chain of department stores\n store-related data (e.g. sales, inventory) stored in store\n corporate data (e.g. HR, customers) stored on central server(s)\n sales data sent to data warehouse for analysis\n",
  "key_words": [
   "distributed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Distributed Databases 47/52\n",
  "content": "In both examples\n some data is conceptually a single table at corporate level\n but does not physically exist as a table in one location\n E.g. account(acct_id, branch, customer, balance)\n each branch maintains its own data (for its accounts)\n set of tuples, all with same branch\n bank also needs a view of all accounts\n",
  "key_words": [
   "distributed",
   "database"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Data Distribution 48/52\n",
  "content": "Partitioning/distributing data\n where to place (parts of) tables\n determined by usage of data  (locality, used together)\n affects communication cost \u21d2 query evaluation cost\n how to partition data within tables\n no partitioning ... whole table stored on \u22651 DBMS\n horizontal partitioning ... subsets of rows\n vertical partitioning ... subsets of columns\n Problem: maintaining consistency\n",
  "key_words": [
   "data",
   "distribution"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Data Distribution 49/52\n",
  "content": "Consider table R decomposed into R1, R2, ..., Rn\n Fragmentation can be done in multiple ways, but need to ensure ...\n Completeness\n decompostion is complete iff each t\u2208R is in some Ri\n Reconstruction\n original R can be produced by some relational operation\n Disjoint\n if item t \u2208 Ri, then t \u2209 Rk, k \u2260 i   (assuming no replication)\n",
  "key_words": [
   "data",
   "distribution"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Query Processing 50/52\n",
  "content": "Query processing typically involves shipping data\n e.g. reconstructing table from distributed partitions\n e.g. join on tables stored on separate sites\n Aim: minimise shipping cost   (since it is a networking cost)\n Shipping cost becomes the \"disk access cost\" of DQOpt\n Larger space of possibilities than standard QOpt, but same principle\n consider possible execution plans, choose cheapest\n",
  "key_words": [
   "query",
   "processing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Processing 51/52\n",
  "content": "Distributed query processing\n may require query ops to be executed on different nodes\n node provides only source of some data\n some nodes may have limited set of operations\n needs to merge data received from different nodes\n may require data transformation (to fit schemas together)\n Query optimisation in such contexts is complex.\n",
  "key_words": [
   "query",
   "processing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Transaction Processing 52/52\n",
  "content": "Distribution of data complicates tx processing ...\n potential for multiple copies of data to become inconsistent\n commit or abort must occur consistently on all nodes\n Distributed tx processing handled by two-phase commit\n initiating site has transaction coordinator Ci ...\n waits for all other sites executing tx T to \"complete\"\n sends <prepare T> message to all other sites\n waits for <ready T> response from all other sites\n if not received (timeout), or <abort T> received, flag abort\n if all other sites respond <ready T>, flag commit\n write <commit T> or <abort T> to log\n send <commit T> or <abort T> to all other sites\n non-initiating sites write log entries before responding\n Produced: 4 Oct 2018\n",
  "key_words": [
   "transaction",
   "processing"
  ],
  "question": null,
  "intent_tag": "unknow"
 }
]