[
 {
  "topic": "Week 6 Lectures",
  "content": "Implementing in PostgreSQL\n",
  "key_words": [
   "week",
   "6",
   "lecture"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Recap on Implementing Selection \n",
  "content": "Selection =  select * from  R  where  C\n yields a subset of R tuples satisfying condition C\n a very important (frequent) operation in relational databases\n Types of selection determined by type of condition\n one:  select * from  R  where id=k\n pmr:  select * from  R  where age=65\n rng:   select * from  R  where age\u226518 and age\u226421\n Strategies for implementing selection efficiently\n arrangement of tuples in file  (e.g. sorting, hashing)\n auxiliary data structures  (e.g. indexes, signatures)\n",
  "key_words": [
   "recap",
   "on",
   "implementing",
   "selection"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Linear Hashing \n",
  "content": "File organisation:\n file of primary data blocks\n file of overflow data blocks\n a register called the split pointer\n Uses systematic method of growing data file ...\n hash function \"adapts\" to changing address range\n systematic splitting controls length of overflow chains\n",
  "key_words": [
   "linear",
   "hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion with Linear Hashing \n",
  "content": "Abstract view:\n P = bits(d,hash(key));\n if (P < sp) P = bits(d+1,hash(key));\n // bucket P = page P + its overflow pages\n for each page Q in bucket P {\n     if (space in Q) { insert into Q; break; }\n }\n if (no insertion) {\n     add new ovflow page to bucket P\n     insert into new page\n }\n if (need to split) {\n     partition tuples from bucket sp\n           into buckets sp and sp+2^d\n     sp++;\n     if (sp == 2^d) { d++; sp = 0; }\n }\n",
  "key_words": [
   "insertion",
   "with",
   "linear",
   "hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Insertion with Linear Hashing \n",
  "content": "Splitting block sp=01:\n",
  "key_words": [
   "insertion",
   "with",
   "linear",
   "hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Insertion with Linear Hashing \n",
  "content": "Splitting algorithm:\n // partitions tuples between two buckets\n newp = sp + 2^d; oldp = sp;\n buf = getPage(f,sp);\n clear(oldBuf); clear(newBuf);\n // start filling data page buffers\n for (i = 0; i < nTuples(buf); i++) {\n     tup = getTuple(buf,i);\n     p = bits(d+1,hash(tup.k));\n     if (p == newp)         addTuple(newBuf,tup);\n     else\n         addTuple(oldBuf,tup);\n }\n ... remove and re-insert tuples from ovflow chain ...\n sp++;\n if (sp == 2^d) { d++; sp = 0; }\n",
  "key_words": [
   "insertion",
   "with",
   "linear",
   "hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion Cost \n",
  "content": "If no split required, cost same as for standard hashing:\n Costinsert  =    Best: 1r + 1w,     Worst: (1+max(Ov))r + 2w\n If split occurs, incur Costinsert  plus cost of splitting:\n read block sp   (plus all of its overflow blocks)\n write block sp   (and its new overflow blocks)\n write block sp+2d   (and its new overflow blocks)\n On average,   Costsplit  =  (1+Ov)r + (2+Ov)w\n",
  "key_words": [
   "insertion",
   "cost"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Deletion with Linear Hashing \n",
  "content": "Deletion is similar to ordinary static hash file.\n But might wish to contract file when enough tuples removed.\n Rationale: r shrinks, b stays large \u21d2 wasted space.\n Method: remove last bucket in data file (contracts linearly).\n Involves a coalesce procedure which is an inverse split.\n",
  "key_words": [
   "deletion",
   "with",
   "linear",
   "hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Hash Files in PostgreSQL \n",
  "content": "PostgreSQL uses linear hashing on tables which have been:\n create index Ix on R using hash (k);\n Hash file implementation: backend/access/hash\n hashfunc.c ... a family of hash functions\n hashinsert.c ... insert, with overflows\n hashpage.c ... utilities + splitting\n hashsearch.c ... iterator for hash files\n Based on \"A New Hashing Package for Unix\", Margo Seltzer, Winter Usenix 1991\n",
  "key_words": [
   "hash",
   "file",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hash Files in PostgreSQL \n",
  "content": "PostgreSQL uses a different file organisation ...\n has a single file containing main and overflow pages\n has groups of size 2n of data pages\n in between groups, arbitrary number of overflow pages\n maintains collection of group pointers in header page\n each group pointer indicates start of data page group\n Also maintain a split pointer for data pages.\n If overflow pages become empty, add to free list and re-use.\n",
  "key_words": [
   "hash",
   "file",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hash Files in PostgreSQL \n",
  "content": "PostgreSQL hash file structure:\n",
  "key_words": [
   "hash",
   "file",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hash Files in PostgreSQL \n",
  "content": "Converting bucket # to page address (adapted from pgsql source):\n typedef unsigned int Word;\n // which page is primary page of bucket B\n Word bucket_to_page(Word splits[], B) {\n    Word chunk, base, offset;\n    chunk = (B<2) ? 0 : lg2(B+1)-1;\n    base = splits[chunk];\n    offset = (B<2) ? B : B-(1<<chunk);\n    return (base + offset);\n }\n // returns ceil(log_2(n))\n int lg2(Word n) {\n    int i, v;\n    for (i = 0, v = 1; v < n; v <= 1) i++;\n    return i;\n }\n",
  "key_words": [
   "hash",
   "file",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Indexing \n",
  "content": "An index is a table/file of (keyVal,tupleID) pairs, e.g.\n",
  "key_words": [
   "indexing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Indexes \n",
  "content": "A 1-d index is based on the value of a single attribute A.\n Some possible properties of A:\n may be used to sort data file   (or may be sorted on some other field)\n values may be unique   (or there may be multiple instances)\n Taxonomy of index types, based on properties of index attribute:\n primary index on unique field, may be sorted on A\n clustering index on non-unique field, file sorted on A\n secondary file not sorted on A\n A given table may have indexes on several attributes.\n",
  "key_words": [
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Indexes \n",
  "content": "Indexes themselves may be structured in several ways:\n dense every tuple is referenced by an entry in the index file\n sparse only some tuples are referenced by index file entries\n single-level tuples are accessed directly from the index file\n multi-level may need to access several index pages to reach tuple\n Index file has total i pages   (where typically i \u226a b)\n Index file has page capacity ci   (where typically ci \u226b c)\n Dense index:  i = ceil( r/ci )     Sparse index:  i = ceil( b/ci )\n",
  "key_words": [
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Dense Primary Index \n",
  "content": "Data file unsorted; one index entry for each tuple\n",
  "key_words": [
   "dense",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Sparse Primary Index \n",
  "content": "Data file sorted; one index entry for each page\n",
  "key_words": [
   "sparse",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Selection with Primary Index \n",
  "content": "For one queries:\n ix = binary search index for entry with key K\n if nothing found { return NotFound }\n b = getPage(pageOf(ix.tid))\n t = getTuple(b,offsetOf(ix.tid))\n    -- may require reading overflow pages\n return t\n Worst case:   read log2i index pages  +  read 1+Ov data pages.\n Thus, Costone,prim  =  log2 i + 1 + Ov\n Assume: index pages are same size as data pages \u21d2 same reading cost\n",
  "key_words": [
   "selection",
   "with",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Selection with Primary Index \n",
  "content": "For range queries on primary key:\n use index search to find lower bound\n read index sequentially until reach upper bound\n accumulate set of buckets to be examined\n examine each bucket in turn to check for matches\n For pmr queries involving primary key:\n search as if performing one query.\n For queries not involving primary key, index gives no help.\n",
  "key_words": [
   "selection",
   "with",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion with Primary Index \n",
  "content": "Overview:\n insert tuple into page P\n find location for new entry in index file\n    // could check whether it already exists\n insert new index entry (k,tid) into index file    // tid = tupleID = (P + offset within page)\n Problem: order of index entries must be maintained\n need to avoid overflow pages in index\n so we need to reorganise index file\n On average, this requires us to read/write half of index file.\n Costinsert,prim  =  (log2i)r + i/2.(1r+1w) + (1+Ov)r + (1+\u03b4)w\n",
  "key_words": [
   "insertion",
   "with",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Deletion with Primary Index \n",
  "content": "Overview:\n find tuple using index\n mark tuple as deleted\n delete index entry for tuple\n If we delete index entries by marking ...\n Costdelete,prim  =  (log2 i + 1 + Ov)r + 2w\n If we delete index entry by index file reorganisation ...\n Costdelete,prim  =  (log2 i + 1 + Ov)r + i/2.(1r+1w) + 1w\n",
  "key_words": [
   "deletion",
   "with",
   "primary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Clustering Index \n",
  "content": "Data file sorted; one index entry for each key value\n",
  "key_words": [
   "clustering",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Clustering Index \n",
  "content": "Index on non-unique ordering attribute Ac.\n Usually a sparse index; one pointer to first tuple containing value.\n Assists with:\n range queries on Ac   (find lower bound, then scan data)\n pmr queries involving Ac   (search index for specified value)\n Insertions are expensive: rearrange index file and data file.\n Deletions relatively cheap (similar to primary index).\n (Note: can't mark index entry for value X until all X tuples are deleted)\n",
  "key_words": [
   "clustering",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Secondary Index \n",
  "content": "Generally, dense index on non-unique attribute As\n data file is not ordered on attribute As\n index file is ordered on attribute As\n Problem: multiple tuples with same value for As.\n A solution:\n dense index (Ix2) containing just TupleId's\n sparse index (Ix1) on dense index containing (key,offset) pairs\n Each offset references an entry in Ix2\n",
  "key_words": [
   "secondary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Secondary Index \n",
  "content": "Costpmr  =  Costrange  =  (log2i + aq2 + bq.(1 + Ov)) Costrange  =  (log2i + aq1 + aq2 + bq.(1 + Ov))\n",
  "key_words": [
   "secondary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion/Deletion with Secondary Index \n",
  "content": "Insertion:\n each insert requires three files to be updated\n potentially costly rearrangement of index files\n Deletion:\n use mark-style (tombstone) deletion for data tuples\n Ix2 entries: can always mark as \"deleted\"\n Ix1 entries: mark only after removing last instance for k in Ix2\n periodic \"vacuum\" to reduce storage overhead if many deletions\n",
  "key_words": [
   "insertion",
   "deletion",
   "with",
   "secondary",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Multi-level Indexes \n",
  "content": "Above Secondary Index used two index files to speed up search\n by keeping the initial index search relatively quick\n Ix1 small (depends on number of unique key values)\n Ix2 larger (depends on amount of repetition of keys)\n typically, bIx1 \u226a bIx2\n Could improve further by\n making Ix1 sparse, since Ix2 is guaranteed to be ordered\n in this case, bIx1 = ceil( bIx2 / ci )\n if Ix1 becomes too large, add Ix3 and make Ix2 sparse\n if data file ordered on key, could make Ix3 sparse\n Ultimately, reduce top-level of index hierarchy to one page.\n",
  "key_words": [
   "multi-level",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Multi-level Indexes \n",
  "content": "Example data file with three-levels of index:\n Assume:  not primary key,  c = 100,  ci = 3\n",
  "key_words": [
   "multi-level",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Select with Multi-level Index \n",
  "content": "For one query on indexed key field:\n I = top level index page\n for level = 1 to d {\n     read index page I\n     search index page for J'th entry\n         where index[J].key <= K < index[J+1].key\n     if J=0 { return NotFound }\n     I = index[J].page\n }\n -- I is now address of data page\n search page I and its overflow pages\n Read d index blocks and 1+Ov data blocks.\n Thus, Costone,mli  =  (d + 1 + Ov)r\n (Note that d = ceil( logci r ) and ci is large because index entries are small)\n",
  "key_words": [
   "select",
   "with",
   "multi-level",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "B-Trees \n",
  "content": "B-trees are MSTs with the properties:\n they are updated so as to remain balanced\n each node has at least (n-1)/2 entries in it\n each tree node occupies an entire disk page\n B-tree insertion and deletion methods\n are moderately complicated to describe\n can be implemented very efficiently\n Advantages of B-trees over general MSTs\n better storage utilisation (around 2/3 full)\n better worst case performance (shallower)\n",
  "key_words": [
   "b-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... B-Trees \n",
  "content": "Example B-tree (depth=3, n=3):\n (Note that nodes are pages, with potential for large branching factor, e.g. n=500)\n",
  "key_words": [
   "b-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "B-Tree Depth \n",
  "content": "Depth depends on effective branching factor  (i.e. how full nodes are).\n Simulation studies show typical B-tree nodes are 69% full.\n Gives   load Li = 0.69 \u00d7 ci   and   depth of tree ~ ceil( logLi r ).\n Example: ci=128,    Li=88\n Level #nodes #keys\n root 1 87\n 1 88 7656\n 2 7744 673728\n 3 681472 59288064\n Note: ci is generally larger than 128 for a real B-tree.\n",
  "key_words": [
   "b-tree",
   "depth"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion into B-Trees \n",
  "content": "Overview of the method:\n 1. find leaf node and position in node where entry would be stored\n 2. if node is not full, insert entry into appropriate spot\n 3. if node is full, split node into two half-full nodes\n                        and promote middle element to parent\n 4. if parent full, split and promote\n Note: if duplicates not allowed and key is found, may stop after step 1.\n",
  "key_words": [
   "insertion",
   "into",
   "b-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Example: B-tree Insertion \n",
  "content": "https://www.youtube.com/watch?v=KdbFmwRvkvg\n",
  "key_words": [
   "example",
   "b-tree",
   "insertion"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "B-Tree Insertion Cost \n",
  "content": "Insertion cost = CosttreeSearch + CosttreeInsert + CostdataInsert\n Best case: write one page (most of time)\n traverse from root to leaf\n read/write data page, write updated leaf\n Costinsert  =  Dr + 1w + 1r + 1w\n Common case: 3 node writes (rearrange 2 leaves + parent)\n traverse from root to leaf, holding nodes in buffer\n read/write data page\n update/write leaf, parent and sibling\n Costinsert  =  Dr + 3w + 1r + 1w\n",
  "key_words": [
   "b-tree",
   "insertion",
   "cost"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... B-Tree Insertion Cost \n",
  "content": "Worst case: 2D-1 node writes (propagate to root)\n traverse from root to leaf, holding nodes in buffers\n read/write data page\n update/write leaf, parent and sibling\n repeat previous step D-1 times\n Costinsert  =  Dr + (2D-1)w + 1r + 1w\n",
  "key_words": [
   "b-tree",
   "insertion",
   "cost"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Selection with B-Trees \n",
  "content": "For one queries:\n N = B-tree root node\n while (N is not a leaf node)\n    N = scanToFindChild(N,K)\n TupleID = scanToFindEntry(N,K)\n access tuple t using TupleID from N\n Costone  =  (D + 1)r\n For range queries (assume sorted on index attribute):\n search index to find leaf node for Lo\n for each leaf node entry until Hi found {\n  access tuple t using TupleId from entry\n }\n Costrange  =  (D + bi + bq)r\n",
  "key_words": [
   "selection",
   "with",
   "b-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "B-trees in PostgreSQL \n",
  "content": "PostgreSQL implements Lehman/Yao-style B-trees.\n A variant that works effectively in high-concurrency environments.\n B-tree implementation: backend/access/nbtree\n nbtree.c ... interface functions (for iterators)\n nbtsearch.c ... traverse index to find key value\n nbtinsert.c ... add new entry to B-tree index\n",
  "key_words": [
   "b-trees",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... B-trees in PostgreSQL \n",
  "content": "Interface functions for B-trees\n // build Btree index on relation\n Datum btbuild(rel,index,...)\n // insert index entry into Btree\n Datum btinsert(rel,key,tupleid,index,...)\n // start scan on Btree index\n Datum btbeginscan(rel,key,scandesc,...)\n // get next tuple in a scan\n Datum btgettuple(scandesc,scandir,...)\n // close down a scan\n Datum btendscan(scandesc)\n N-dimensional Selection\n",
  "key_words": [
   "b-trees",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "N-dimensional Queries \n",
  "content": "Have looked at one-dimensional queries, e.g.\n select * from R where a = K\n select * from R where a between Lo and Hi\n and heaps, hashing, indexing as ways of efficient implementation.\n Now consider techniques for efficient multi-dimensional queries.\n Compared to 1-d queries, multi-dimensional queries\n typically produce fewer results\n require us to consider more information\n require more effort to produce results\n",
  "key_words": [
   "n-dimensional",
   "query"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Operations for Nd Select \n",
  "content": "N-dimensional select queries = condition on \u22651 attributes.\n pmr = partial-match retrieval (equality tests), e.g.\n select * from Employees\n where  job = 'Manager' and gender = 'M';\n space = tuple-space queries (range tests), e.g.\n select * from Employees\n where 20 \u2264 age \u2264 50 and 40K \u2264 salary \u2264 60K\n",
  "key_words": [
   "operation",
   "for",
   "nd",
   "select"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "N-d Selection via Heaps \n",
  "content": "Heap files can handle pmr or space using standard method:\n // select * from R where C\n r = openRelation(\"R\",READ);\n for (p = 0; p < nPages(r); p++) {\n     buf = getPage(file(r), p);\n     for (i = 0; i < nTuples(buf); i++) {\n         t = getTuple(buf,i);\n         if (matches(t,C))\n             add t to result set\n     }\n }\n Costpmr  =  Costspace  =  b\n",
  "key_words": [
   "n-d",
   "selection",
   "via",
   "heap"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "N-d Selection via Multiple Indexes \n",
  "content": "DBMSs already support building multiple indexes on a table.\n Which indexes to build depends on which queries are asked.\n create table R (a int, b int, c int);\n create index Rax on R (a);\n create index Rbx on R (b);\n create index Rcx on R (c);\n create index Rabx on R (a,b);\n create index Racx on R (a,c);\n create index Rbcx on R (b,c);\n create index Rallx on R (a,b,c);\n But more indexes \u21d2 space + update overheads.\n",
  "key_words": [
   "n-d",
   "selection",
   "via",
   "multiple",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "N-d Queries and Indexes \n",
  "content": "Generalised view of pmr and space queries:\n select * from R\n where  a1 op1 C1 and ... and an opn Cn pmr : all opi are equality tests.     space : some opi are range tests.\n Possible approaches to handling such queries ...\n 1. use index on one ai to reduce tuple tests\n 2. use indexes on all ai, and intersect answer sets\n",
  "key_words": [
   "n-d",
   "query",
   "and",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... N-d Queries and Indexes \n",
  "content": "If using just one of several indexes, which one to use?\n select * from R\n where  a1 op1 C1 and ... and an opn Cn The one with best selectivity for ai opi Ci   (i.e. fewest matches)\n Factors determining selectivity of ai opi Ci\n assume uniform distribution of values in dom(ai)\n equality test on primary key gives at most one match\n equality test on larger dom(ai) \u21d2 less matches\n range test over large part of dom(ai) \u21d2 many matches\n",
  "key_words": [
   "n-d",
   "query",
   "and",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... N-d Queries and Indexes \n",
  "content": "Implementing selection using one of several indices:\n // Query: select * from R where a1op1C1 and ... and anopnCn\n // choose ai with best selectivity\n TupleIDs = IndexLookup(R,ai,opi,Ci)\n // gives { tid1, tid2, ...} for tuples satisfying aiopiCi\n PageIDs = { }\n foreach tid in TupleIDs\n    { PageIDs = PageIDs \u222a {pageOf(tid)} }\n // PageIDs = a set of bqix page numbers\n ...\n Cost = Costindex + bqix    (some pages do not contain answers, bqix > bq)\n DBMSs typically maintain statistics to assist with determining selectivity\n",
  "key_words": [
   "n-d",
   "query",
   "and",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... N-d Queries and Indexes \n",
  "content": "Implementing selection using multiple indices:\n // Query: select * from R where a1op1C1 and ... and anopnCn\n // assumes an index on at least ai\n TupleIDs = IndexLookup(R,a1,op1,C1)\n foreach attribute ai with an index {\n    tids = IndexLookup(R,ai,opi,Ci)\n    TupleIDs = TupleIDs \u2229 tids\n }\n PageIDs = { }\n foreach tid in TupleIDs\n    { PageIDs = PageIDs \u222a {pageOf(tid)} }\n // PageIDs = a set of bq page numbers\n ...\n Cost = k.Costindex + bq     (assuming indexes on k of n attrs)\n",
  "key_words": [
   "n-d",
   "query",
   "and",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Bitmap Indexes \n",
  "content": "Alternative index structure, focussing on sets of tuples:\n Index contains bit-strings of r bits, one for each value/range\n",
  "key_words": [
   "bitmap",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Bitmap Indexes \n",
  "content": "Answering queries using bitmap index:\n Matches = AllOnes(r)\n foreach attribute A with index {\n    // select ith bit-string for attribute A\n    // based on value associated with A in WHERE\n    Matches = Matches & Bitmaps[A][i]\n }\n // Matches contains 1-bit for each matching tuple\n foreach i in 0..r {\n    if (Matches[i] == 0) continue;\n    t = fetchTuple(i)\n    Results = Results \u222a {t}\n }\n",
  "key_words": [
   "bitmap",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Bitmap Indexes \n",
  "content": "Storage costs for bitmap indexes:\n one bitmap for each value/range for each indexed attribute\n each bitmap has length ceil(r/8) bytes\n e.g. with 50K records and 8KB pages, bitmap fits in one page\n Query execution costs for bitmap indexes:\n read one bitmap for each indexed attribute in query\n perform bitwise AND on bitmaps (in memory)\n read pages containing matching tuples\n Note: bitmaps could index pages (shorter bitmaps, more comparisons)\n",
  "key_words": [
   "bitmap",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Hashing and pmr \n",
  "content": "For a pmr query like\n select * from R where a1 = C1 and ... and an = Cn\n if one ai is the hash key, query is very efficient\n if no ai is the hash key, need to use linear scan\n Can be alleviated using multi-attribute hashing (mah)\n form a composite hash value involving all attributes\n at query time, some components of composite hash are known (allows us to limit the number of data pages which need to be checked)\n MA.hashing works in conjunction with any dynamic hash scheme.\n",
  "key_words": [
   "hashing",
   "and",
   "pmr"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Hashing and pmr \n",
  "content": "Multi-attribute hashing parameters:\n file size = b = 2d pages   \u21d2   use d-bit hash values\n relation has n attributes:   a1, a2, ...an\n attribute ai has hash function hi\n attribute ai contributes di bits (to the combined hash value)\n total bits d = \u2211i=1n di\n a choice vector (cv) specifies for all k ... bit j from hi(ai) contributes bit k in combined hash value\n",
  "key_words": [
   "hashing",
   "and",
   "pmr"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "MA.Hashing Example \n",
  "content": "Consider relation Deposit(branch,acctNo,name,amount)\n Assume a small data file with 8 main data pages (plus overflows).\n Hash parameters:    d=3     d1=1    d2=1    d3=1    d4=0\n Note that we ignore the amount attribute (d4=0)\n Assumes that nobody will want to ask queries like\n select * from Deposit where amount=533\n Choice vector is designed taking expected queries into account.\n",
  "key_words": [
   "ma.hashing",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... MA.Hashing Example \n",
  "content": "Choice vector:\n This choice vector tells us:\n bit 0 in hash comes from bit 0 of hash1(a1)   ( b1,0 )\n bit 1 in hash comes from bit 0 of hash2(a2)   ( b2,0 )\n bit 2 in hash comes from bit 0 of hash3(a3)   ( b3,0 )\n bit 3 in hash comes from bit 1 of hash1(a1)   ( b1,1 )\n etc. etc. etc.   (up to as many bits of hashing as required, e.g. 32)\n",
  "key_words": [
   "ma.hashing",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... MA.Hashing Example \n",
  "content": "Consider the tuple:\n branch acctNo name amount\n Downtown 101 Johnston 512\n Hash value (page address) is computed by:\n",
  "key_words": [
   "ma.hashing",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "MA.Hashing Hash Functions \n",
  "content": "Auxiliary definitions:\n #define MaxHashSize 32\n typedef unsigned int HashVal;\n // extracts i'th bit from hash value\n #define bit(i,h) (((h) & (1 << (i))) >> (i))\n // choice vector elems\n typedef struct { int attr, int bit } CVelem;\n typedef CVelem ChoiceVec[MaxHashSize];\n // hash function for individual attributes\n HashVal hash1(Tuple t, int i) { ... }\n",
  "key_words": [
   "ma.hashing",
   "hash",
   "function"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... MA.Hashing Hash Functions \n",
  "content": "Produce combined d-bit hash value for tuple t:\n HashVal hash(Tuple t, ChoiceVec cv, int d)\n {\n     HashVal h[nAttr(t)+1];  // hash for each attr\n     HashVal res = 0, oneBit;\n     int     i, a, b;\n     for (i = 1; i <= nAttr(t); i++)\n         h[i] = hash1(t,i);\n     for (i = 0; i < d; i++) {\n         a = cv[i].attr;\n         b = cv[i].bit;\n         oneBit = bit(b, h[a]);\n         res = res | (oneBit << i);\n     }\n     return res;\n }\n",
  "key_words": [
   "ma.hashing",
   "hash",
   "function"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Exercise 5: Multi-attribute Hashing \n",
  "content": "Compute the hash value for the tuple\n ('John Smith','BSc(CompSci)',1990,99.5)\n where d=6,   d1=3,   d2=2,   d3=1, and\n cv = <(1,0), (1,1), (2,0), (3,0), (1,2), (2,1), (3,1), (1,3), ...>\n hash1('John Smith') = ...0101010110110100\n hash2('BSc(CompSci)') = ...1011111101101111\n hash3(1990) = ...0001001011000000\n",
  "key_words": [
   "exercise",
   "5",
   "multi-attribute",
   "hashing"
  ],
  "question": null,
  "intent_tag": "exercise"
 },
 {
  "topic": "Queries with MA.Hashing \n",
  "content": "In a partial match query:\n values of some attributes are known\n values of other attributes are unknown\n E.g.\n select amount\n from   Deposit\n where  branch = 'Brighton' and name = 'Green'\n for which we use the shorthand   (Brighton, ?, Green, ?)\n",
  "key_words": [
   "query",
   "with",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Queries with MA.Hashing \n",
  "content": "In composite hash for query, values for some bits are unknown:\n What this tells us: any matching tuples must be in pages 101, 111\n",
  "key_words": [
   "query",
   "with",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Queries with MA.Hashing \n",
  "content": "Consider the query:\n select amount from Deposit where name = 'Green'\n Need to check pages: 100, 101, 110, 111.\n",
  "key_words": [
   "query",
   "with",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "MA.Hashing Query Algorithm \n",
  "content": "// Builds the partial hash value (e.g. 10*0*1)\n // Treats query like tuple with some attr values missing\n nstars = 0;\n for each attribute i in query Q {\n     if (hasValue(Q,i)) {\n         set d[i] bits in composite hash\n             using choice vector and hash(Q,i)\n     } else {\n         set d[i] *'s in composite hash\n             using choice vector\n         nstars++;\n     }\n }\n ...\n",
  "key_words": [
   "ma.hashing",
   "query",
   "algorithm"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... MA.Hashing Query Algorithm \n",
  "content": "...\n // Use the partial hash to find candidate pages\n r = openRelation(\"R\",READ);\n for (i = 0; i < 2**nstars; i++) {\n     P = composite hash\n     replace *'s in P\n         using i and choice vector\n     Buf = readPage(file(r), P);\n     for each tuple T in Buf {\n         if (T satisfies pmr query)\n             add T to results\n     }\n }\n",
  "key_words": [
   "ma.hashing",
   "query",
   "algorithm"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Query Cost for MA.Hashing 74/102\n",
  "content": "Multi-attribute hashing handles a range of query types, e.g.\n select * from R where a=1\n select * from R where d=2\n select * from R where b=3 and c=4\n select * from R where a=5 and b=6 and c=7\n A relation with n attributes has 2n different query types.\n Different query types have different costs   (different no. of *'s)\n Query distribution gives probability pQ of asking each query type Q.\n",
  "key_words": [
   "query",
   "cost",
   "for",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Cost for MA.Hashing \n",
  "content": "For a relation  R(a,b,c,d)  ...\n select * from R where a=1\n -- has 1 specified attribute (a)\n -- has 3 unspecified attributes (b,c,d)\n select * from R where b=5 and d=2\n -- has 2 specified attributes (b,d)\n -- has 2 unspecified attributes (a,c)\n select * from R\n where a=1 and b=5 and c=3 and d=2\n -- has 4 specified attributes (a,b,c,d)\n -- has 0 unspecified attributes\n",
  "key_words": [
   "query",
   "cost",
   "for",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Cost for MA.Hashing \n",
  "content": "Consider a query of type Q with m attributes unspecified.\n Each unspecified Ai contributes di *'s.\n Total number of *'s is   s  =  \u2211i \u2209 Q di.\n \u21d2 Number of pages to read is   2s  =  \u220fi \u2209 Q 2di.\n Ignoring overflows, Cost(Q) = 2s    (where s is determined by Q)\n Including overflows, Cost(Q) = 2s(1+Ov)\n",
  "key_words": [
   "query",
   "cost",
   "for",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Query Cost for MA.Hashing \n",
  "content": "Min query cost occurs when all attributes are used in query\n Min Costpmr  =  1\n Max query cost occurs when no attributes are specified\n Max Costpmr  =  2d  =  b\n Average cost is given by weighted sum over all query types:\n Avg Costpmr  =  \u2211Q pQ \u220fi \u2209 Q 2di\n Aim to minimise the weighted average query cost over possible query types\n",
  "key_words": [
   "query",
   "cost",
   "for",
   "ma.hashing"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Optimising MA.Hashing Cost \n",
  "content": "For a given application, useful to minimise Costpmr.\n Can be achieved by choosing appropriate values for di   (cv)\n Heuristics:\n distribution of query types (more bits to frequently used attributes)\n size of attribute domain (\u2264 #bits to represent all values in domain)\n discriminatory power (more bits to highly discriminating attributes)\n Trade-off: making query type Qj more efficient makes Qk less efficient.\n This is a combinatorial optimisation problem, and can be handled by standard optimisation techniques e.g. simulated\n annealing.\n",
  "key_words": [
   "optimising",
   "ma.hashing",
   "cost"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "MA.Hashing Cost Example \n",
  "content": "Consider a table with four attributes:\n (branch, account, name, amount)   (abbreviated to (br,ac,nm,amt) )\n Possible query types, and likelhood of each:\n Query type Cost pQ\n (?, ?, ?, ?) 8 0\n (br, ?, ?, ?) 4 0.25\n (?, ac, ?, ?) 4 0\n (br, ac, ?, ?) 2 0\n (?, ?, nm, ?) 4 0\n (br, ?, nm, ?) 2 0\n (?, ac, nm, ?) 2 0.25\n (br, ac, nm, ?) 1 0\n (?, ?, ?, amt) 8 0\n (br, ?, ?, amt) 4 0\n (?, ac, ?, amt) 4 0\n (br, ac, ?, amt) 2 0\n (?, ?, nm, amt) 4 0\n (br, ?, nm, amt) 2 0.5\n (?, ac, nm, amt) 2 0\n (br, ac, nm, amt) 1 0\n Cost values are based on choice vector   (dbr = dac = dnm = 1) pQ values can be determined by observation of DB use.\n",
  "key_words": [
   "ma.hashing",
   "cost",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... MA.Hashing Cost Example \n",
  "content": "Consider r=106, Nr=100, b=104, d=14.\n Attribute br occurs in 0.5+0.25 used query types \u21d2 allocate many bits to it e.g. d1=6.\n Attribute nm occurs in 0.5+0.25 of queries \u21d2 allocate many bits to it e.g. d3=4.\n Attribute amt occurs in 0.5 of queries \u21d2 allocate less bits to it e.g. d4=2.\n Attribute ac occurs in 0.25 of queries \u21d2 allocate least bits to it e.g. d2=2.\n",
  "key_words": [
   "ma.hashing",
   "cost",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "... MA.Hashing Cost Example \n",
  "content": "With bits distributed as: d1=6, d2=2, d3=4, d4=2\n Query type Cost pQ\n (br, ?, ?, ?) 28 = 256 0.25\n (?, ac, nm, ?) 28 = 256 0.25\n (br, ?, nm, amt) 22 = 4 0.5\n Cost  =  0.5 \u00d7 22 + 0.25 \u00d7 28 + 0.25 \u00d7 28  =  130\n",
  "key_words": [
   "ma.hashing",
   "cost",
   "example"
  ],
  "question": null,
  "intent_tag": "example"
 },
 {
  "topic": "Multi-dimensional Tree Indexes \n",
  "content": "Over the last 20 years, from a range of problem areas\n different multi-d tree index schemes have been proposed\n varying primarily in how they partition tuple-space\n Consider three popular schemes:   kd-trees, Quad-trees, R-trees.\n Example data for multi-d trees is based on the following relation:\n create table Rel (\n     X char(1) check (X between 'a' and 'z'),\n     Y integer check (Y between 0 and 9)\n );\n",
  "key_words": [
   "multi-dimensional",
   "tree",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Multi-dimensional Tree Indexes \n",
  "content": "Example tuples:\n Rel('a',1)  Rel('a',5)  Rel('b',2)  Rel('d',1)\n Rel('d',2)  Rel('d',4)  Rel('d',8)  Rel('g',3)\n Rel('j',7)  Rel('m',1)  Rel('r',5)  Rel('z',9)\n The tuple-space for the above tuples:\n",
  "key_words": [
   "multi-dimensional",
   "tree",
   "index"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "kd-Trees \n",
  "content": "kd-trees are multi-way search trees where\n each level of the tree partitions on a different attribute\n each node contains n-1 key values, pointers to n subtrees\n",
  "key_words": [
   "kd-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... kd-Trees \n",
  "content": "",
  "key_words": [
   "kd-trees"
  ],
  "question": [
   "How this tree partitions the tuple space?"
  ],
  "intent_tag": "unknow"
 },
 {
  "topic": "Searching in kd-Trees \n",
  "content": "// Started by Search(Q, R, 0, kdTreeRoot)\n Search(Query Q, Relation R, Level L, Node N)\n {\n    if (isDataPage(N)) {\n       Buf = getPage(fileOf(R),idOf(N))\n       check Buf for matching tuples\n    } else {\n       a = attrLev[L]\n       if (!hasValue(Q,a))\n          nextNodes = all children of N\n       else {\n          val = getAttr(Q,a)\n          nextNodes = find(N,Q,a,val)\n       }\n       for each C in nextNodes\n          Search(Q, R, L+1, C)\n }  }\n",
  "key_words": [
   "searching",
   "in",
   "kd-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Quad Trees \n",
  "content": "Quad trees use regular, disjoint partitioning of tuple space.\n for 2d, partition space into quadrants (NW, NE, SW, SE)\n each quadrant can be further subdivided into four, etc.\n Example:\n",
  "key_words": [
   "quad",
   "tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Quad Trees \n",
  "content": "Basis for the partitioning:\n a quadrant that has no sub-partitions is a leaf quadrant\n each leaf quadrant maps to a single data page\n subdivide until points in each quadrant fit into one data page\n ideal: same number of points in each leaf quadrant (balanced)\n point density varies over space \u21d2 different regions require different levels of partitioning\n this means that the tree is not necessarily balanced\n Note: effective for d\u22645, ok for 6\u2264d\u226410, ineffective for d>10\n",
  "key_words": [
   "quad",
   "tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... Quad Trees \n",
  "content": "The previous partitioning gives this tree structure, e.g.\n In this and following examples, we give coords of top-left,bottom-right of a region\n",
  "key_words": [
   "quad",
   "tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Searching in Quad-tree \n",
  "content": "Space query example:\n Need to traverse: red(NW), green(NW,NE,SW,SE), blue(NE,SE).\n",
  "key_words": [
   "searching",
   "in",
   "quad-tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "R-Trees \n",
  "content": "R-trees use a flexible, overlapping partitioning of tuple space.\n each node in the tree represents a kd hypercube\n its children represent (possibly overlapping) subregions\n the child regions do not need to cover the entire parent region\n Overlap and partial cover means:\n can optimize space partitioning wrt data distribution\n so that there are similar numbers of points in each region\n Aim: height-balanced, partly-full index pages   (cf. B-tree)\n",
  "key_words": [
   "r-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "... R-Trees \n",
  "content": "",
  "key_words": [
   "r-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Insertion into R-tree \n",
  "content": "Insertion of an object R occurs as follows:\n start at root, look for children that completely contain R\n if no child completely contains R, choose one of the children and expand its boundaries so that it does contain\n R\n if several children contain R, choose one and proceed to child\n repeat above containment search in children of current node\n once we reach data page, insert R if there is room\n if no room in data page, replace by two data pages\n partition existing objects between two data pages\n update node pointing to data pages (may cause B-tree-like propagation of node changes up into tree)\n Note that R may be a point or a polygon.\n",
  "key_words": [
   "insertion",
   "into",
   "r-tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Query with R-trees \n",
  "content": "Designed to handle space queries and \"where-am-I\" queries.\n \"Where-am-I\" query: find all regions containing a given point P:\n start at root, select all children whose subregions contain P\n if there are zero such regions, search finishes with P not found\n otherwise, recursively search within node for each subregion\n once we reach a leaf, we know that region contains P\n Space (region) queries are handled in a similar way\n we traverse down any path that intersects the query region\n",
  "key_words": [
   "query",
   "with",
   "r-trees"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Multi-d Trees in PostgreSQL \n",
  "content": "Up to version 8.2, PostgreSQL had R-tree implementation\n Superseded by GiST = Generalized Search Trees\n GiST indexes parameterise: data type, searching, splitting\n via seven user-defined functions (e.g. picksplit())\n GiST trees have the following structural constraints:\n every node is at least fraction f full (e.g. 0.5)\n the root node has at least two children (unless also a leaf)\n all leaves appear at the same level\n Details: src/backend/access/gist\n",
  "key_words": [
   "multi-d",
   "tree",
   "in",
   "postgresql"
  ],
  "question": null,
  "intent_tag": "unknow"
 },
 {
  "topic": "Costs of Search in Multi-d Trees \n",
  "content": "Difficult to determine cost precisely.\n Best case: pmr query where all attributes have known values\n in kd-trees and quad-trees, follow single tree path\n cost is equal to depth D of tree\n in R-trees, may follow several paths (overlapping partitions)\n Typical case: some attributes are unknown or defined by range\n need to visit multiple sub-trees\n how many depends on: range, choice-points in tree nodes\n Produced: 30 Aug 2018\n",
  "key_words": [
   "cost",
   "of",
   "search",
   "in",
   "multi-d",
   "tree"
  ],
  "question": null,
  "intent_tag": "unknow"
 }
]